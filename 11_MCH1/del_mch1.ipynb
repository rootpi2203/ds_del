{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning - MCH1\n",
    "Fachdozent: Martin Melchior     \n",
    "Student: Manuel Schwarz   \n",
    "HS23\n",
    "\n",
    "Dieses Notebook bearbeitet die Mini-Challenge 1 des Moduls Deep Learning (del).   \n",
    "Die Performance der Modelle wurde mit **wandb.ai** aufgezeichnet und kann [hier](https://wandb.ai/manuel-schwarz/del-mc1/workspace?workspace=user-manuel-schwarz) eingesehen werden.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Aufgabenstellung:</b> Eine Blaue Box beschreibt die Aufgabe aus der Aufgabenstellung 'SGDS_DEL_MC1.pdf' \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Antworte:</b> Eine Grüne Box beschreibt die Bearbeitung / Reflektion der Aufgabenstellung\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import torch\n",
    "import wandb\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm \n",
    "from datetime import datetime\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.model_selection import KFold\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device: ', device)\n",
    "\n",
    "# sound\n",
    "import time\n",
    "import winsound\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schritt 1: Auswahl Task / Datensatz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "1. Mache Dir Gedanken, mit welchen Daten Du arbeiten möchtest und welcher Task gelernt werden soll.\n",
    "    \n",
    "2. Diskutiere die Idee mit dem Fachcoach.\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten und Task\n",
    "Pytorch stellt einige Datensets zur Verfügung [datasets torch](https://pytorch.org/vision/main/datasets.html).\n",
    "Verschiedene Kategorien stehen zur Auswahl:\n",
    "- Image classification\n",
    "- Image detection or segmentation\n",
    "- Optical Flow\n",
    "- Stereo Matching\n",
    "- Image pairs\n",
    "- Image captioning\n",
    "- video classification\n",
    "- Base classes for custom datasets\n",
    "\n",
    "\n",
    "**Datenset**  \n",
    "Eine beliebtes Datenset ist CIFAR10. Es beinhaltet Bilder von 10 Klassen (Flugzeuge, Katzen, Vögel, etc.), die Bilder kommen mit einer Auflösung von 32x32x3 pixel (rgb). Viele Tutorials starten mit diesem Datenset, das lässt darauf schliessen, dass der Rechenaufwand für die Hardware in einem vernünpftigen Rahmen liegt. Daher wird CIFAR10 als Datenset für diese Challenge verwendet.\n",
    "\n",
    "**Task**  \n",
    "Anhand von CIFAR10 soll ein Modell erstellt werden, welches die Klasse eines Bildes korrekt klassifiziert.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](cifar10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schritt 2: Daten Kennenlernen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "1. Mache Dich mit dem Datensatz vertraut, indem Du eine explorative Analyse der Features durchführst: z.B. Vergleich der Klassen pro Feature, Balanciertheit der Klassen. \n",
    "2. Führe ein geeignetes Preprocessing durch, z.B. Normalisierung der Daten.  \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Explorative Datenanalyse\n",
    "[Tutorial Dataloader](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden der Daten von CIFAR10\n",
    "data_path = './data/'\n",
    "train_data = torchvision.datasets.CIFAR10(data_path, train=True, download=True)\n",
    "\n",
    "test_data = torchvision.datasets.CIFAR10(data_path, train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datengrösse der Trainings- und Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Anzahl Trainingsdaten: {len(train_data)}\\n'\n",
    "      f'Anzahl Testdaten: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wie sind die Bilder im Datensatz gespeichert?**  \n",
    "Die Bilder sind direkt auf dem Datenset via dem Index abrufbar. Ein Tupel mit dem Bild (RGB, 32x32 pixel) und dem Label (6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_0, label_0 = train_data[0]\n",
    "img_0, label_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deffinieren der Labels CIFAR10\n",
    "labels_cifar10_dict = {\n",
    "    0: \"airplane\",\n",
    "    1: \"automobile\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\",\n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\",\n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\",\n",
    "}\n",
    "labels_cifar10_list = list(labels_cifar10_dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualisierung der Bilder**  \n",
    "Die Bilder können mit matplotlib und imshow() direkt vom Dateset über den index dargestellt werden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(6,6))\n",
    "cols, rows = 5, 5\n",
    "\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
    "    img, label = train_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_cifar10_list[label], fontsize=8)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Untersuchen der Verteilungen der Klassen**  \n",
    "Folgend werden die Verteilungen der Klassen der Cifar10 Datensets auf den Trainings- und Testdaten geprüft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train_data.targets\n",
    "test_target = test_data.targets\n",
    "print(f'Labels in Trainingsdaten: {len(train_target)}')\n",
    "print(f'Labels in Testdaten: {len(test_target)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(1,2, figsize=(10, 3))\n",
    "\n",
    "ax[0].hist(train_target)\n",
    "ax[0].set_xticks(np.arange(10))\n",
    "ax[0].set_xticklabels(labels_cifar10_list, rotation=45)\n",
    "ax[0].set_title('Trainingset', fontsize=8)\n",
    "\n",
    "ax[1].hist(test_target)\n",
    "ax[1].set_xticks(np.arange(10))\n",
    "ax[1].set_xticklabels(labels_cifar10_list, rotation=45)\n",
    "ax[1].set_title('Testset', fontsize=8)\n",
    "\n",
    "plt.suptitle('Verteilung der Klassen von Cifar-10', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "Das Trainingsset umfasst total 50'000 Bilder, davon sind jeweils 5000 Bilder jeder Klasse enthalten (Balanced Datenset). Somit kann zum Beispiel eine Metrik wie 'Accuracy' verwendet werden, um die Klassifikation der Modelle zu beurteilen und zu vergleichen. Die 10'000 Bilder in den Testdaten sind ebenfalls gleich verteilt.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mittelwerte und Standardabweichungen des Trainingdatensets (RGB):\n",
    "Benötigt um die Daten zu normalisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle Datenset mit Tensoren für Berechnunen\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_data = torchvision.datasets.CIFAR10(data_path, train=True, download=False, transform=transform)\n",
    "test_data = torchvision.datasets.CIFAR10(data_path, train=False, download=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_std_dataset(train_data, print_info=True):\n",
    "    '''\n",
    "    Berechnet den Mittelwert und Standardabweichung für alle Bilder\n",
    "    '''\n",
    "    num_images = len(train_data)\n",
    "\n",
    "    pixel_values = np.zeros((num_images, 3, 32, 32), dtype=np.float32)\n",
    "\n",
    "    for i in range(num_images):\n",
    "        image, _ = train_data[i]\n",
    "        pixel_values[i] = image.numpy()\n",
    "\n",
    "    mean = np.mean(pixel_values, axis=(0, 2, 3))\n",
    "    std = np.std(pixel_values, axis=(0, 2, 3))\n",
    "\n",
    "    if print_info:\n",
    "        print(\"RGB-Mittelwerte:\", mean)\n",
    "        print(\"RGB-Standardabweichungen:\", std)\n",
    "\n",
    "calc_mean_std_dataset(train_data, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing der Daten  \n",
    "Folgend werden die Daten in einem Preprocessing Schritt für die Modelle vorbereitet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cross_validation_loaders(dataset, kfold, train_batch_size, test_batch_size):\n",
    "    '''\n",
    "    todo: fix CV Fehler\n",
    "    '''\n",
    "    cv_train_loader = []\n",
    "    cv_test_loader = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kfold.split(dataset)):\n",
    "        # train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "        # val_subsampler = torch.utils.data.SubsetRandomSampler(test_idx)       \n",
    "        \n",
    "        # train_loader = torch.utils.data.DataLoader(dataset, \n",
    "        #                 batch_size=train_batch_size, \n",
    "        #                 sampler=train_subsampler,\n",
    "        #                 shuffle=True)\n",
    "        # val_loader = torch.utils.data.DataLoader(dataset,\n",
    "        #                 batch_size=test_batch_size,\n",
    "        #                 sampler=val_subsampler,\n",
    "        #                 shuffle=False)\n",
    "        \n",
    "\n",
    "        train_subsampler = torch.utils.data.Subset(dataset, train_idx)\n",
    "        val_subsampler = torch.utils.data.Subset(dataset, test_idx)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_subsampler, \n",
    "                        batch_size=train_batch_size, \n",
    "                        shuffle=True)\n",
    "        val_loader = torch.utils.data.DataLoader(val_subsampler,\n",
    "                        batch_size=test_batch_size,\n",
    "                        shuffle=False)\n",
    "        \n",
    "        cv_train_loader.append(train_loader)\n",
    "        cv_test_loader.append(val_loader)\n",
    "    return cv_train_loader, cv_test_loader\n",
    "\n",
    "# function preprocessing\n",
    "def preprocessing_cifar10(path='./data/', train_batch_size=32, test_batch_size=32, normalize='zero_one',\n",
    "                          norm_mean=(0.4914009  , 0.548215896, 0.4465308), \n",
    "                          norm_std=(0.24703279 , 0.24348423 , 0.26158753), \n",
    "                          download=True, print_info=False, cv=False, k_folds=5, \n",
    "                          set_seed=42):\n",
    "    \n",
    "    if print_info: print(f'------------'), print(f'Preprocessing start')\n",
    "\n",
    "    if normalize == 'zero_one':\n",
    "        # transform tensor to normalized range [0, 1], 0=schwarz\n",
    "        transform = transforms.Compose([transforms.ToTensor()])\n",
    "    elif normalize == 'minusone_one':\n",
    "        # transform tensor to normalized range [-1, 1], 0=schwarz\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize(norm_mean, norm_std)])\n",
    "    elif normalize == 'None':\n",
    "        transform = transforms.Compose([])\n",
    "    else:\n",
    "        raise ValueError('Nomalize must be either \"zero_one\", \"minusone_one\" or \"None\"') \n",
    "    \n",
    "    if cv:\n",
    "        dataset_train = torchvision.datasets.CIFAR10(root=path, train=True, download=download, transform=transform)        \n",
    "        dataset_test = torchvision.datasets.CIFAR10(root=path, train=False, download=download, transform=transform)\n",
    "        dataset = dataset = torch.utils.data.ConcatDataset([dataset_train, dataset_test])\n",
    "\n",
    "        if print_info: \n",
    "            print(f'Data transformed: {normalize}')\n",
    "            calc_mean_std_dataset(dataset, print_info)\n",
    "        \n",
    "        kfold = KFold(n_splits=k_folds, shuffle=True, random_state=set_seed)        \n",
    "\n",
    "        cv_train_loader, cv_test_loader = get_cross_validation_loaders(\n",
    "            dataset, kfold, train_batch_size, test_batch_size)\n",
    "        \n",
    "        if print_info: print(f'Dataloader created with {train_batch_size=}, {test_batch_size=}')\n",
    "        if print_info: print(f'Preprocessing done'), print('------------')\n",
    "\n",
    "        return cv_train_loader, cv_test_loader\n",
    "\n",
    "    else:\n",
    "        # CIFAR10: 50000 32x32 color images in 10 classes, with 5000 images per class\n",
    "        train_dataset = torchvision.datasets.CIFAR10(root=path, train=True,\n",
    "                                                download=download, transform=transform)\n",
    "        test_dataset = torchvision.datasets.CIFAR10(root=path, train=False,\n",
    "                                            download=download, transform=transform)\n",
    "        if print_info: \n",
    "            print(f'Data transformed: {normalize}')\n",
    "            calc_mean_std_dataset(train_dataset, print_info)\n",
    "\n",
    "        # dataloader\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "        if print_info: print(f'Dataloader created with {train_batch_size=}, {test_batch_size=}')\n",
    "        if print_info: print(f'Preprocessing done'), print('------------')   \n",
    "\n",
    "        return train_dataset, test_dataset, train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/'\n",
    "batch_size = 32\n",
    "transform = 'zero_one' # minusone_one\n",
    "\n",
    "train_dataset, test_dataset, train_loader, test_loader = preprocessing_cifar10(\n",
    "    path=data_path, \n",
    "    train_batch_size=batch_size,\n",
    "    test_batch_size=batch_size,\n",
    "    normalize=transform,  \n",
    "    download=False,  \n",
    "    print_info=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "data_path = './data/'\n",
    "batch_size = 32\n",
    "transform = 'zero_one' # minusone_one\n",
    "\n",
    "cv_train_loader, cv_test_loader = preprocessing_cifar10(\n",
    "    train_batch_size=batch_size,\n",
    "    test_batch_size=batch_size,\n",
    "    normalize=transform,\n",
    "    download=False,  \n",
    "    print_info=False, cv=True\n",
    "    )\n",
    "\n",
    "print(f'K Fold CV: {len(cv_train_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Aus den Berechnungen des Mittelwert und Standardabweichung lässt sich schliessen dass die Daten von Cifar-10 bereits normalisiert wurden auf Werte zwischen [0,1]. Mit der Transformation im Preprocessing `transforms.Normalize(mean, std)` können die Werte in den Bereich [-1, 1] gesetzt werden. Welcher Wertebereich die bessere Wahl ist, ist Situationsbedingt (z.B. verwendete Aktivierungsfunktion). Eine Zentrierung um Null kann für Netze Vorteile haben, hingegen sind Werte zwischen [0,1] besser zu interpretieren (0=schwarz, 1=RGB 255). Vorerst soll mit dem Wertebereich [0,1] gearbeitet werden.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schritt 3: Aufbau Modellierung  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "1. Lege fest, wie (mit welchen Metriken) Du die Modelle evaluieren möchtest. Berücksichtige auch den Fehler in der Schätzung dieser Metriken.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Die Klassengrössen sind ausbalanciert, daher ist für die Metrik **Accuracy** für die Modell Beurteilung geeignet und soll hier für die Modellbewertung zum Einsatz kommen:\n",
    "\n",
    "$$ Accuracy = \\frac{Anzahl\\ korrekte\\ Klassifizierungen}{Total\\ Klassifizierungen}  $$\n",
    "\n",
    "Für eine Klassifizierung von mehr als zwei Klassen eignet sich **CrossEntropyLoss**. Mehr dazu [hier](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html):\n",
    "\n",
    "$$ \\text{CrossEntropyLoss} = -\\sum_{i=1}^{N} \\left[ y_i \\log(\\hat{y_i}) + (1 - y_i) \\log(1 - \\hat{y_i}) \\right] $$\n",
    "\n",
    "\n",
    "Die Accuracy berechnet eine Schätzung. Bei der Initialisierung der Modellgewichte werden Zufallswerte verwendet. Auch die Wahl der Bilder innerhalb der Batchsize wird durch `shuffle=True` zufällig getroffen *(siehe `Preprocessing`)*. Somit varriert die Accuracy nach jedem Modeltraining ein wenig. Cross-Validation würde sich hier anbieten, um auf k-folds unterschiedliche Modelle zu erstellen. Auch ein Modell mehrmals ausführen, zu unterschiedlichen Seeds, wäre denkbar. Mit dem berechneten Mittelwert $\\mu$ und der Standardabweichung $\\sigma$ kann ein Fehlerabschätzung gemacht werde.  \n",
    "$$ Fehler_{range} = [\\mu - \\sigma; \\mu + \\sigma]$$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "2. Implementiere Basisfunktionalität, um Modelle zu trainieren und gegeneinander zu evaluieren. Wie sollen die Gewichte initialisiert werden?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Die Methode wie die Intitialisierung der Gewichte stattfindet hat Einfluss wie schnell das Modell konvergiert und hilft die Probleme wie `vanishing` oder `exploding` Gradienten abzuschwächen. Kleine zufällige Werte führen zu einem effizienteren Training. Grosse Werte führen zu Problemenn bei dem das Modell nicht oder nur sehr langsam konvergiert. Je nach Problemstellung und Modelarchitekture können unterschiedliche Initialisierungsmethoden verwendet werden\n",
    "\n",
    "Mit der Verwendung von `nn.init` (Pytorch) stehen zum Beispiel folgende Optionen zur Verfügung:\n",
    "1. **Uniform initialization** (help prevents: vanishing gradient, can suffer: exploding gradient)\n",
    "1. **Xavier initialization** (help prevent: vanishing gradient)\n",
    "1. **Kaiming initialization** (help prevent: vanishing gradient, account activation function)\n",
    "1. **Normal initialization** (help prevent: exploding gradient)\n",
    "1. **Zeros initialization** (can suffer: slow converge, vanishing gradient)\n",
    "1. **One’s initialization** (can suffer: slow converge, vanishing gradient)\n",
    "\n",
    "Die genaue Beschreibung der Intitialisierungen können [hier](https://www.geeksforgeeks.org/initialize-weights-in-pytorch/) gefunden werden. Eine eigene Custom-Option stellt Pytorch auch zur Verfügung.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition Helper Functions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "set_seed()\n",
    "\n",
    "def plot_loss_epoch(num_epochs, loss, figsize=(8, 4)):\n",
    "    figure = plt.figure(figsize=figsize)\n",
    "    plt.plot(np.arange(num_epochs), loss)\n",
    "    plt.xticks(np.arange(num_epochs))\n",
    "    plt.title('Loss Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "\n",
    "def calc_true_predictions(output_model, true_labels):\n",
    "    _, predicted = torch.max(output_model.data, 1)\n",
    "    return (predicted == true_labels).sum().item()\n",
    "\n",
    "def measure_model_time(start_time, calc='min'):\n",
    "    model_time = np.round(((time.time() - start_time) / 60), 2)  # from seconds to minute\n",
    "    return model_time\n",
    "\n",
    "def play_sound(typ=0):\n",
    "    # play 'finish' sound\n",
    "    if typ==0:\n",
    "        winsound.PlaySound('../01_Dokumentation/win_sounds/beep.wav', winsound.SND_ASYNC)\n",
    "    if typ==1:\n",
    "        winsound.PlaySound('../01_Dokumentation/win_sounds/beep2.wav', winsound.SND_ASYNC)\n",
    "\n",
    "def plot_init_weights(model, method, figsize=(6, 5)):\n",
    "    l1_weights = model.state_dict()['linear1.weight'].numpy()\n",
    "    l2_weights = model.state_dict()['linear2.weight'].numpy()\n",
    "    fig, ax = plt.subplots(1,2, figsize=figsize)\n",
    "\n",
    "    ax[0].hist(l1_weights.flatten(), bins=50)\n",
    "    ax[1].hist(l2_weights.flatten(), bins=50)\n",
    "\n",
    "    ax[0].set_title(\"Layer 1\", fontsize=8)\n",
    "    ax[0].set_xlabel(\"Gewichtswert\", fontsize=6)\n",
    "    ax[0].set_ylabel(\"Anzahl\", fontsize=8)\n",
    "    ax[0].tick_params(axis='y', labelsize=6)\n",
    "    ax[0].tick_params(axis='x', labelsize=6)\n",
    "    ax[1].set_title(\"Layer 2\", fontsize=8)\n",
    "    ax[1].set_xlabel(\"Gewichtswert\", fontsize=6)\n",
    "    ax[1].tick_params(axis='y', labelsize=6)\n",
    "    ax[1].tick_params(axis='x', labelsize=6)\n",
    "    plt.suptitle(f'Verteilung Initialisierungs Methode: {method}', fontsize=8)\n",
    "    plt.show()\n",
    "\n",
    "def test_eval_plot():\n",
    "    num_epochs = 10\n",
    "    n_loss_epochs = (0.05 * np.sqrt(np.arange(10))) * -1\n",
    "    n_correct_train = 0.1 * n_loss_epochs**4\n",
    "    n_correct_test = 0.05 * n_loss_epochs**4\n",
    "    # create dataloader\n",
    "    train_dataset, test_dataset, train_loader, test_loader = preprocessing_cifar10(batch_size=4,\n",
    "                                                                                norm_mean=(0.5, 0.5, 0.5), \n",
    "                                                                                norm_std=(0.5, 0.5, 0.5),\n",
    "                                                                                download=False,  \n",
    "                                                                                print_info=False)\n",
    "    eval_model(num_epochs, n_loss_epochs, n_correct_train, n_correct_test,\n",
    "                train_loader, test_loader)\n",
    "# test_eval_plot()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitionen Evaluation  \n",
    "Die Ergebnisse eines Modeltrainings werden in einem Plot festgehalten und gespeichert. Für die Diskusion der Modelle werden jedoch die Plots von wandb.ai verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(num_epochs, n_loss_epochs, n_val_loss_epochs, \n",
    "                n_acc_train_epochs, n_acc_test_epochs, train_loader, test_loader, \n",
    "                n_loss_batches=None, group_name='group_name', tag_name='tag_name', figsize=(8,5),\n",
    "                print_info=True, save_image=False):\n",
    "    \n",
    "    epoch = np.arange(num_epochs)\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=figsize)\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    ax1.plot(epoch, n_loss_epochs, color= 'grey', linestyle='--', label='Train Loss')\n",
    "    ax1.plot(epoch, n_val_loss_epochs, color= 'grey', label='Test Loss')\n",
    "    ax2.plot(epoch, n_acc_train_epochs, color='steelblue', label='Accuracy Train')\n",
    "    ax2.plot(epoch, n_acc_test_epochs, color='coral', label='Accuracy Test')\n",
    "    \n",
    "    ax1.set_xticks(epoch)\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss') \n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax1.tick_params(axis='x', labelsize=8)\n",
    "    ax1.tick_params(axis='y', labelsize=8)\n",
    "    ax2.tick_params(axis='y', labelsize=8)\n",
    "    ax1.legend(loc='upper center', bbox_to_anchor=(0.25, -0.12), ncol=3)    \n",
    "    ax2.legend(loc='upper center', bbox_to_anchor=(0.72, -0.12), ncol=3)\n",
    "    \n",
    "    plt.suptitle(f'Training: {group_name} ')\n",
    "    cur_date = datetime.now().strftime(\"%d.%m.%Y_%H%M\")\n",
    "    plt.title(f'{cur_date} - Tags: {tag_name}', size=6)\n",
    "    plt.grid()\n",
    "    if save_image: \n",
    "            plt.savefig(f'./plots/eval_model_plots/{cur_date}_{group_name}_{tag_name}.png')\n",
    "    plt.show()\n",
    "\n",
    "    if print_info:\n",
    "        print(f'Accuracy Train {n_acc_train_epochs[-1]:2f}')\n",
    "        print(f'Accuracy Test {n_acc_test_epochs[-1]:4f}')\n",
    "        print(f'Loss Train {n_loss_epochs[-1]:2f}')\n",
    "        print(f'Loss Test {n_val_loss_epochs[-1]:2f}')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitionen Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Hyperparameters example\n",
    "config = {\n",
    "    \"name\": \"MLP\", \n",
    "    \"epochs\": 20,   \n",
    "    \"train_batch_size\": 32, \n",
    "    \"test_batch_size\": 32,\n",
    "    \"dataset\": \"CIFAR-10\",\n",
    "    \"lr\": 1e-3, \n",
    "    \"optimizer\": 'SGD',\n",
    "    \"Regularisierung\": 'None',  # 'None', 'L1', 'L2',\n",
    "    \"L1_lambda\":0,\n",
    "    \"L2_weight_decay\":0,\n",
    "    \"loss_func\": 'CrossEntropyLoss',\n",
    "    \"activation\": \"ReLU\",\n",
    "    \"image_size\": 32,\n",
    "    \"cross_validation\": False,\n",
    "    \"is_test_batch\": True,\n",
    "    \"start_time\": datetime.now().strftime(\"%d.%m.%Y_%H%M\"),\n",
    "    \"num_workers\": 0,\n",
    "    \"normalize\":\"zero_one\",\n",
    "    \"init_w_method\":\"kaiming_norm\",  #['uniform', 'xavier', 'normal' ,'kaiming_norm' ]\n",
    "    \"hidden_layer_sizes\": [128],\n",
    "    \"filter_sizes\": [32, 64],\n",
    "    \"dense_layers\": [512],\n",
    "    \"kernel_sizes\": 3,\n",
    "    \"padding\": 1,\n",
    "    \"stride\": 1,\n",
    "    \"pool_sizes\": [],\n",
    "    \"dropout\": 0,\n",
    "    \"norm_mean\": (0.5, 0.5, 0.5),\n",
    "    \"norm_std\": (0.5, 0.5, 0.5),\n",
    "    \"num_classes\": 10,\n",
    "    \"save_eval_image\": True,\n",
    "    \"set_seed\": 42\n",
    "}\n",
    "\n",
    "\n",
    "# Train model function\n",
    "def train_model(\n",
    "        model, train_loader, test_loader, config, tags=['tag_name'], group='group_name',\n",
    "        print_info=False, plot_eval=True, sound=False, write_wandb=True, fold=0):      \n",
    "    \n",
    "    set_seed(config['set_seed'])\n",
    "\n",
    "    # Device configuration\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "    if print_info: print(f'------------'), print(f'Starten des Trainings auf Device {device}')\n",
    "\n",
    "    # Model to device\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    # define Loss and Optimizer\n",
    "    if config['loss_func'] == 'CrossEntropyLoss':\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        if print_info: print(f\"Loss Funktion: {config['loss_func']}\")\n",
    "\n",
    "    if config['optimizer'] == 'SGD':        \n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=config['lr'])\n",
    "        if print_info: print(f\"Optimizer: {config['optimizer']} mit lr: {config['lr']}\")\n",
    "    if config['optimizer'] == 'SGD' and config['Regularisierung'] == 'L2':        \n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=config['lr'], weight_decay=config['L2_weight_decay'] )\n",
    "        if print_info: print(f\"Optimizer: {config['optimizer']} mit lr: {config['lr']}, w_decay:{config['L2_weight_decay']}\")\n",
    "        \n",
    "    if config['optimizer']  == 'Adam':        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "        if print_info: print(f\"Optimizer: {config['optimizer']} mit lr: {config['lr']}\")\n",
    "    if config['optimizer']  == 'Adam' and config['Regularisierung'] == 'L2':        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], weight_decay=config['L2_weight_decay'])\n",
    "        if print_info: print(f\"Optimizer: {config['optimizer']} mit lr: {config['lr']}\")\n",
    "\n",
    "    # Initialize wandb\n",
    "    if write_wandb: \n",
    "        cv_model_name = f\"{config['name']}-CV-{fold+1}/{config['n_folds']}-{config['epochs']}-epochs-{config['optimizer']}-{config['start_time']}\"\n",
    "        model_name = f\"{config['name']}-{config['epochs']}-epochs-{config['optimizer']}-{config['start_time']}\"\n",
    "        wandb.init(\n",
    "            project=\"del-mc1\",\n",
    "            entity='manuel-schwarz',\n",
    "            group=group,\n",
    "            name=cv_model_name if config['cross_validation'] else model_name,\n",
    "            tags=tags + (['is_test_batch'] if config['is_test_batch'] else []),\n",
    "            config=config\n",
    "        )\n",
    "\n",
    "    # --------------------- train loop --------------------------\n",
    "    if write_wandb:\n",
    "        wandb.watch(model)\n",
    "\n",
    "    n_loss_epochs = []\n",
    "    n_val_loss_epochs = []\n",
    "    n_loss_all_batches = []\n",
    "    n_val_loss_all_batches = []\n",
    "    n_correct_train_epochs = []\n",
    "    n_correct_test_epochs = []\n",
    "    n_acc_train_epochs = []\n",
    "    n_acc_test_epochs = []\n",
    "\n",
    "    best_train_loss = 0\n",
    "    best_val_loss = 0\n",
    "    best_train_acc = 0\n",
    "    best_test_acc = 0\n",
    "    best_epoch = 0\n",
    "\n",
    "    loop = range(config[\"epochs\"])\n",
    "    epoch_loop = tqdm(loop, desc=\"Epochs\", position=0, leave=True)\n",
    "\n",
    "    for epoch in epoch_loop:\n",
    "        true_train = 0\n",
    "        n_loss_batch = []\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            if config['is_test_batch'] and i > 1:\n",
    "                break\n",
    "            # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
    "            # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # L1-Regularisierung\n",
    "            if config[\"Regularisierung\"] == 'L1':\n",
    "                l1_loss = sum(p.abs().sum() for p in model.parameters())\n",
    "                loss = loss + config[\"L1_lambda\"] * l1_loss\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            n_loss_batch.append(loss.item())\n",
    "            true_train += calc_true_predictions(outputs, labels)\n",
    "            # acc_train = true_train / len(train_loader.dataset)\n",
    "            n_loss_all_batches.append(loss.item())\n",
    "\n",
    "            inner_progress = f\"{i+1}/{len(train_loader)}\"\n",
    "            epoch_loop.set_description(f\"Epochs (Batch: {inner_progress})\")\n",
    "            epoch_loop.refresh()\n",
    "\n",
    "        # save results\n",
    "        acc_train = true_train / len(train_loader.dataset)\n",
    "        epoch_loss = np.mean(n_loss_batch)\n",
    "\n",
    "        n_correct_train_epochs.append(true_train)        \n",
    "        n_acc_train_epochs.append(acc_train)  \n",
    "        n_loss_epochs.append(epoch_loss)\n",
    "\n",
    "        # ---------- eval\n",
    "        model.eval()\n",
    "        true_test_val = 0 \n",
    "        n_val_loss_batch = []\n",
    "        # n_val_pred = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (images, labels) in enumerate(test_loader):\n",
    "                if config['is_test_batch'] and i > 1:\n",
    "                    break\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                n_val_loss_batch.append(loss.item())\n",
    "                true_test_val += calc_true_predictions(outputs, labels)\n",
    "                n_val_loss_all_batches.append(loss.item())              \n",
    "                # _, predicted = torch.max(outputs, 1)  # prediction speichern todo\n",
    "\n",
    "        # save results\n",
    "        acc_test = true_test_val / len(test_loader.dataset)\n",
    "        epoch_val_loss = np.mean(n_val_loss_batch)\n",
    "\n",
    "        n_correct_test_epochs.append(true_test_val)\n",
    "        n_acc_test_epochs.append(acc_test) \n",
    "        n_val_loss_epochs.append(epoch_val_loss)\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        # best scores\n",
    "        if epoch_loss < best_train_loss:\n",
    "            best_train_loss = epoch_loss\n",
    "\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "\n",
    "        if acc_train > best_train_acc:\n",
    "            best_train_acc = acc_train\n",
    "\n",
    "        if acc_test > best_test_acc:\n",
    "            best_test_acc = acc_test\n",
    "            best_epoch = epoch\n",
    "\n",
    "        # log metrics to wandb\n",
    "        if write_wandb:\n",
    "            wandb.log({\n",
    "                \"loss epoch\": epoch_loss, \n",
    "                \"validation loss epoch\": epoch_val_loss, \n",
    "                \"acc_train\": acc_train, \n",
    "                \"acc_test\": acc_test,\n",
    "                })\n",
    "    if write_wandb:\n",
    "            wandb.log({\n",
    "                \"best_epoch\": best_epoch,\n",
    "                \"best_train_loss\": best_train_loss,\n",
    "                \"best_val_loss\": best_val_loss,\n",
    "                \"best_acc_train\": best_train_acc,\n",
    "                \"best_acc_test\": best_test_acc,\n",
    "                })\n",
    "\n",
    "    acc_train = n_correct_train_epochs[-1] / len(train_loader.dataset)\n",
    "    acc_test = n_correct_test_epochs[-1] / len(test_loader.dataset)\n",
    "\n",
    "    if plot_eval:\n",
    "        eval_model(config['epochs'], n_loss_epochs, n_val_loss_epochs, \n",
    "                    n_acc_train_epochs, n_acc_test_epochs, train_loader, test_loader,\n",
    "                    group_name=group, tag_name=tags, print_info=print_info, \n",
    "                    save_image=config['save_eval_image']\n",
    "                    )\n",
    "        \n",
    "    print(\n",
    "            f\"Epoch {epoch + 1}/{config['epochs']}, \\\n",
    "            Loss: {round(epoch_loss, 5)}, Validation Loss: {round(epoch_val_loss, 5)} \\\n",
    "            Acc: {round(acc_train, 5)}, Validation Acc: {round(acc_test, 5)}\"\n",
    "            )\n",
    "    \n",
    "    if sound: play_sound(1)\n",
    "\n",
    "    if write_wandb: \n",
    "        wandb.finish()\n",
    "        time.sleep(5)  # wait for wandb.finish\n",
    "\n",
    "    print('Finished Training')\n",
    "    return epoch_loss, epoch_val_loss, acc_train, acc_test\n",
    "\n",
    "\n",
    "def model_trainer(model, config=config, group='group_name', tags=['tag1'],\n",
    "                print_info=False, plot_eval=True, sound=True, \n",
    "                write_wandb=True, download=False):\n",
    "    \n",
    "    if config['cross_validation']:\n",
    "        cv_train_loader, cv_test_loader = preprocessing_cifar10(\n",
    "            train_batch_size=config[\"train_batch_size\"],\n",
    "            test_batch_size=config[\"test_batch_size\"],\n",
    "            normalize=config['normalize'],\n",
    "            download=download,  \n",
    "            print_info=print_info, cv=True,\n",
    "            set_seed=config['set_seed']\n",
    "            )\n",
    "        \n",
    "        cv_train_acc = []\n",
    "        cv_test_acc = []\n",
    "\n",
    "        for fold, (train_loader, test_loader) in enumerate(zip(cv_train_loader, cv_test_loader)):\n",
    "            _, _, train_acc, test_acc = train_model(model, train_loader, test_loader, config=config,\n",
    "                    group=group,\n",
    "                    tags=tags,\n",
    "                    print_info=print_info, plot_eval=plot_eval, sound=sound, \n",
    "                    write_wandb=write_wandb, fold=fold\n",
    "                    )\n",
    "            \n",
    "            cv_train_acc.append(train_acc)\n",
    "            cv_test_acc.append(test_acc)\n",
    "\n",
    "        cv_train_acc_mean = np.mean(cv_train_acc)\n",
    "        cv_test_acc_mean = np.mean(cv_test_acc)\n",
    "\n",
    "        return cv_train_acc_mean, cv_test_acc_mean, cv_train_acc, cv_test_acc\n",
    "\n",
    "    else:\n",
    "        # create dataloader\n",
    "        _, _, train_loader, test_loader = preprocessing_cifar10(\n",
    "            train_batch_size=config[\"train_batch_size\"],\n",
    "            test_batch_size=config[\"test_batch_size\"],\n",
    "            normalize=config['normalize'],\n",
    "            download=download,  \n",
    "            print_info=print_info,\n",
    "            set_seed=config['set_seed']\n",
    "            )\n",
    "\n",
    "            # train model\n",
    "        _, _, train_acc, test_acc = train_model(model, train_loader, test_loader, config=config,\n",
    "                    group=group,\n",
    "                    tags=tags,\n",
    "                    print_info=print_info, plot_eval=plot_eval, sound=sound, \n",
    "                    write_wandb=write_wandb\n",
    "                    )\n",
    "        return train_acc, test_acc, 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einfacher Modell Test  \n",
    "Folgend soll ein einfaches Modell mit einem hidden Layer erstellt werden um die Basisfunktionen von `model_trainer()` zu testen. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple model Class\n",
    "class MLPNet_hl1(nn.Module):\n",
    "    def __init__(self, hidden_l_1:list, act_fn=F.relu, dropout=0, init_methode:str='kaiming_norm'):\n",
    "        super(MLPNet_hl1, self).__init__()\n",
    "        self.linear1 = nn.Linear(3*32*32, hidden_l_1[0])  # input.shape = (n, 3, 32, 32)\n",
    "        self.linear2 = nn.Linear(hidden_l_1[0], 10)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = act_fn \n",
    "\n",
    "        for linear_weight in [self.linear1.weight, self.linear2.weight]:          \n",
    "            if init_methode == 'uniform':\n",
    "                torch.nn.init.uniform_(linear_weight)\n",
    "            if init_methode == 'xavier':\n",
    "                torch.nn.init.xavier_uniform_(linear_weight)\n",
    "            if init_methode == 'normal':\n",
    "                torch.nn.init.normal_(linear_weight, mean=0, std=1)\n",
    "            if init_methode == 'kaiming_norm':\n",
    "                torch.nn.init.kaiming_normal_(linear_weight, nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x): # x.shape = (n, 3, 32, 32)\n",
    "        x = x.view(-1, 3*32*32) # x.shape = (n, 3072)\n",
    "        x = self.activation(self.linear1(x)) # x.shape = (3072, 128)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x) # x.shape = (128, 10)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initilisierung Gewichte: \n",
    "Da unterschiedliche Problemstellung verschiedene Initialisierungen erfordern, sollen mehrere Methoden von Pytorch ausprobiert werden um die Gewichte zu initialisiern: Folgende Grafik zeigt die Gewichte des ersten (initial) und zweiten Layers:\n",
    "1. `uniform`: torch.nn.init.uniform_(linear_layer.weight)\n",
    "1. `xavier`: torch.nn.init.xavier_uniform_(linear_layer.weight)\n",
    "1. `normal`: torch.nn.init.normal_(linear_layer.weight, mean=0, std=1)\n",
    "1. `kaiming_norm`: torch.nn.init.kaiming_normal_(linear_layer.weight, nonlinearity=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_lst = ['uniform', 'xavier', 'normal' ,'kaiming_norm' ]\n",
    "# create model\n",
    "for method in method_lst:\n",
    "    model = MLPNet_hl1(hidden_l_1=[64], init_methode=method)\n",
    "    plot_init_weights(model, method, figsize=(6, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Verteilungen der Gewichte mit den Methoden `uniform` und  `xavier` sind sehr ähnlich. Mit Xavier ist die X-Skala unterschiedlich, da die Gewichte so skalliert werden dass die Varianz des Output der Varianz des Inputs entspricht. Bei `normal` und `kaiming_norm` besteht das gleiche Prinzip, die Skallierung der Gewichte, weiter wird die Aktivierungsfunktion berücksichtigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    from datetime import datetime\n",
    "    # Hyperparameters  \n",
    "    config = {\n",
    "        \"name\": \"MLP-test1\", \n",
    "        \"epochs\": 1,   \n",
    "        \"train_batch_size\": 32, \n",
    "        \"test_batch_size\": 32,\n",
    "        \"dataset\": \"CIFAR-10\",\n",
    "        \"lr\": 1e-3, \n",
    "        \"optimizer\": 'SGD',\n",
    "        \"Regularisierung\": 'None',  # 'None', 'L1', 'L2',\n",
    "        \"L1_lambda\":0,\n",
    "        \"L2_weight_decay\":0,\n",
    "        \"loss_func\": 'CrossEntropyLoss',\n",
    "        \"loss_func\": 'CrossEntropyLoss',\n",
    "        \"activation\": \"ReLU\",\n",
    "        \"image_size\": 32,\n",
    "        \"cross_validation\": False,\n",
    "        \"n_folds\": 5,\n",
    "        \"is_test_batch\": True,\n",
    "        \"start_time\": datetime.now().strftime(\"%d.%m.%Y_%H%M\"),\n",
    "        \"num_workers\": 0,\n",
    "        \"normalize\":\"zero_one\",\n",
    "        \"init_w_method\":\"kaiming_norm\",  #['uniform', 'xavier', 'normal' ,'kaiming_norm' ]\n",
    "        \"hidden_layer_sizes\": [128],\n",
    "        \"filter_sizes\": [32, 64],\n",
    "        \"dense_layers\": [512],\n",
    "        \"kernel_sizes\": 3,\n",
    "        \"padding\": 1,\n",
    "        \"stride\": 1,\n",
    "        \"pool_sizes\": [],\n",
    "        \"dropout\": 0,\n",
    "        \"norm_mean\": (0.5, 0.5, 0.5),\n",
    "        \"norm_std\": (0.5, 0.5, 0.5),\n",
    "        \"num_classes\": 10,\n",
    "        \"save_eval_image\": True,\n",
    "        \"set_seed\": 42\n",
    "    }\n",
    "\n",
    "    # create model\n",
    "    model2 = MLPNet_hl1(\n",
    "        hidden_l_1=config[\"hidden_layer_sizes\"], \n",
    "        act_fn=F.relu,\n",
    "        dropout=0,\n",
    "        init_methode=config[\"init_w_method\"],\n",
    "        )\n",
    "\n",
    "    cv_train_acc_mean, cv_test_acc_mean, _, _ = model_trainer(model2, config=config,\n",
    "                    group='MLP_CV_test2',\n",
    "                    tags=['MLP', 'cv-test'],\n",
    "                    print_info=False, plot_eval=False, sound=True, \n",
    "                    write_wandb=False\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schritt 4: Evaluation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "Bei der Evaluation ist darauf zu achten, dass das Vorgehen stets möglichst reflektiert erfolgt und versucht wird, die Ergebnisse zu interpretieren. Am Schluss soll auch ein Fazit gezogen werden, darüber welche Variante am besten funktioniert.  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**1. Training mit SGD, ohne REG, ohne BN:**  \n",
    "Untersuche verschiedene Modelle unterschiedlicher Komplexität, welche geeignet sein könnten, um das Klassifikationsproblem zu lösen. Verwende Stochastic Gradient Descent - ohne Beschleunigung, ohne Regularisierung (REG) und ohne Batchnorm (BN).  \n",
    "\n",
    "a. Für jedes Modell mit gegebener Anzahl Layer und Units pro Layer führe ein sorgfältiges Hyper-Parameter-Tuning durch (Lernrate, Batch-Grösse). Achte stets darauf, dass das Training stabil läuft. Merke Dir bei jedem Training, den Loss, die Performance Metrik(en) inkl. Schätzfehler, die verwendete Anzahl Epochen, Lernrate und Batch-Grösse.\n",
    "\n",
    "b. Variiere die Anzahl Layer und Anzahl Units pro Layer, um eine möglichst gute Performance zu erreichen. Falls auch CNNs (ohne Transfer-Learning) verwendet werden variiere auch Anzahl Filter, Kernel-Grösse, Stride, Padding.\n",
    "\n",
    "c. Fasse die Ergebnisse zusammen in einem geeigneten Plot, bilde eine Synthese und folgere, welche Modell-Komplexität Dir am sinnvollsten erscheint.  \n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MLP** Hyperparameter Suche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für ein gutes Modell müssen optimale Hyperparamter gefunden werden. Folgende werden MLP-Modelle mit unterschiedlichen Anzahl und Grösse von Layers erstellt. Zu jedem Modell soll weiter den Einfluss von Lernrate und Batchsize untersucht werden:\n",
    "\n",
    "**Ablauf pro Modell:**  \n",
    "1. Der Umfang sowie die Anzahl der hidden Layers werden gesetzt\n",
    "1. Pro Modell werden verschiedene Lernraten untersucht\n",
    "1. Pro Modell werden verschiedene Grössen von Layern untersucht\n",
    "1. Pro Modell werden verschiedene Batchgrössen untersucht\n",
    "\n",
    "Das Tracking von Loss und Metriken werden mit wandb für jedes Training aufgezeichnet. Bildauschnitte des Trainings wurden zur Diskusion hinzugefügt.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MLP mit einem hidden Layer**  \n",
    "In den folgenden Experimenten soll die Lernrate, die Grösse des hidden Layers und die Batchsize untersucht werden:\n",
    "\n",
    "|Experiment| Lernrate | Grösse hL1 | Batchsize |\n",
    "|---|----------|----------|----------|\n",
    "|1| 1e-1, 1e-2, 1e-3, 1e-4, 1e-5 | 128*  | 32*  |\n",
    "|2| 1e-2** | 64, 128, 256, 512, 1024 |  32* |\n",
    "|3| 1e-2** | 1024**  | 4, 16, 32, 64, 128  |\n",
    "\n",
    "Info:  \n",
    "(\\*) gewählter Startwert    \n",
    "(\\*\\*) optimaler Wert    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPNet_hl1(nn.Module):\n",
    "    def __init__(self, h_layer_sizes:list, input_size=3*32*32, act_fn=F.relu, dropout=0, \n",
    "                init_methode:str='kaiming_norm', output_size=10):\n",
    "        super(MLPNet_hl1, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, h_layer_sizes[0])  # input.shape = (n, 3, 32, 32)\n",
    "        self.linear2 = nn.Linear(h_layer_sizes[0], 10)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = act_fn \n",
    "\n",
    "        for linear_weight in [self.linear1.weight, self.linear2.weight]:          \n",
    "            if init_methode == 'uniform':\n",
    "                torch.nn.init.uniform_(linear_weight)\n",
    "            if init_methode == 'xavier':\n",
    "                torch.nn.init.xavier_uniform_(linear_weight)\n",
    "            if init_methode == 'normal':\n",
    "                torch.nn.init.normal_(linear_weight, mean=0, std=1)\n",
    "            if init_methode == 'kaiming_norm':\n",
    "                torch.nn.init.kaiming_normal_(linear_weight, nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x): # x.shape = (n, 3, 32, 32)\n",
    "        x = x.view(-1, 3*32*32) # x.shape = (n, 3072)\n",
    "        x = self.activation(self.linear1(x)) # x.shape = (3072, 128)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x) # x.shape = (128, 10)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    from datetime import datetime\n",
    "\n",
    "    #for lr in [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]:\n",
    "    #for hl_size in [64, 128, 256, 512, 1024]:\n",
    "    #for bt_size in [4, 16, 32, 64, 128]:\n",
    "    for seed in [12, 16, 42, 64, 71]:\n",
    "        # Hyperparameters  \n",
    "        config = {\n",
    "            \"name\": \"MLP-hL1\", \n",
    "            \"epochs\": 15,   \n",
    "            \"train_batch_size\": 32, \n",
    "            \"test_batch_size\": 32,\n",
    "            \"dataset\": \"CIFAR-10\",\n",
    "            \"lr\": 1e-2, # default 1e-3\n",
    "            \"optimizer\": 'SGD',\n",
    "            \"Regularisierung\": 'None',  # 'None', 'L1', 'L2',\n",
    "            \"L1_lambda\":0,\n",
    "            \"L2_weight_decay\":0,\n",
    "            \"loss_func\": 'CrossEntropyLoss',\n",
    "            \"loss_func\": 'CrossEntropyLoss',\n",
    "            \"activation\": \"ReLU\",\n",
    "            \"image_size\": 32,\n",
    "            \"cross_validation\": False,\n",
    "            \"n_folds\": 5,\n",
    "            \"is_test_batch\": False,\n",
    "            \"start_time\": datetime.now().strftime(\"%d.%m.%Y_%H%M\"),\n",
    "            \"num_workers\": 0,\n",
    "            \"normalize\":\"zero_one\",\n",
    "            \"init_w_method\":\"kaiming_norm\",  #['uniform', 'xavier', 'normal' ,'kaiming_norm' ]\n",
    "            \"hidden_layer_sizes\": [1024],\n",
    "            \"filter_sizes\": [32, 64],\n",
    "            \"dense_layers\": [512],\n",
    "            \"kernel_sizes\": 3,\n",
    "            \"padding\": 1,\n",
    "            \"stride\": 1,\n",
    "            \"pool_sizes\": [],\n",
    "            \"dropout\": 0,\n",
    "            \"norm_mean\": (0.5, 0.5, 0.5),\n",
    "            \"norm_std\": (0.5, 0.5, 0.5),\n",
    "            \"num_classes\": 10,\n",
    "            \"save_eval_image\": True,\n",
    "            \"set_seed\": seed  # [12, 16, 42, 64, 71]\n",
    "        }\n",
    "\n",
    "        # create model\n",
    "        mlp_h1 = MLPNet_hl1(\n",
    "            h_layer_sizes=config[\"hidden_layer_sizes\"], \n",
    "            act_fn=F.relu,\n",
    "            dropout=0,\n",
    "            init_methode=config[\"init_w_method\"],\n",
    "            )\n",
    "\n",
    "        cv_train_acc_mean, cv_test_acc_mean, _, _ = model_trainer(mlp_h1, config=config,\n",
    "                        group=f'MLP_hL1_seed_val',  # _5f_cv, _seed_val\n",
    "                        tags=['MLP', 'seed val'],  # 5fold cv, seed val\n",
    "                        print_info=False, plot_eval=True, sound=True, \n",
    "                        write_wandb=True\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unterschiedliche Lernraten**\n",
    "\n",
    "<img src=\"../01_Dokumentation/wandb_images/MLP_hl1_lr.PNG\" width=\"800\" height=\"400\">\n",
    "\n",
    "**Unterschiedliche Layergrösse**\n",
    "\n",
    "<img src=\"../01_Dokumentation/wandb_images/MLP_hl1_layer_size.PNG\" width=\"900\" height=\"400\">\n",
    "\n",
    "**Unterschiedliche Batchgrösse**\n",
    "\n",
    "<img src=\"../01_Dokumentation/wandb_images/MLP_hl1_batch_size.PNG\" width=\"900\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "**Einfluss der Learningrate:**  \n",
    "Die Lernrate bestimmt, wie stark die Modellgewichte in jedem Trainingsschritt angepasst werden. $$ W_{neu}= W_{alt} - Lernrate \\cdot Gradient $$\n",
    "Bei einer zu hohen Lernrate kann es passieren, dass das optimale globale Minimum übersprungen wird. Das Training könnte auch divergieren statt konvergieren. Bei einer zu tiefen Lernrate kann das Training an einem lokalen Minimum hängen bleiben und das globale Minimum nicht erreichen. Auch findet der Trainingsprozess weniger schnell statt. Das ist auch der Grund der tieferen Accuracy bei den verschiedenen Lernraten, tiefere Lernraten müssten mit mehr Epochen trainiert werden. Bei $lr=1^{-2}$ erreicht das Training die höchste Accuracy, wobei der Verlauf etwas weniger stabil aussieht. Die Lernraten $1^{-1}$ und $1^{-3}$ sind sehr ähnlich. Ein Optimum wurde bei $1^{-2}$ gefunden. \n",
    "\n",
    "\n",
    "**Einfluss Grösse des Hidden Layers:**  \n",
    "Ein Modell mit einem hidden Layer verbindet den Input Layer mit dem Output Layer. In unserem Fall $Input\\ Layer (Bild): 3*32*32 = 3072 -> hidden\\ Layer -> Output\\ Layer (Anzahl\\ Klassen) = 10$. Die Lernrate wurde auf $1^{-2}$ gesetzt. In der  Entwicklung von Trainings Loss und der Training Accuracy zeigt sich ein sehr ähnliches Verhalten. Die Test Accuracy zeigt, dass eine sehr tiefe Layergrösse weniger gut geeignet ist. Die Unterschiede ab Grösse 256 sind weniger markant. Eine Layergrösse von 1024 zeigte die beste Accuracy. Grössere Layer können besser komplexe Funktionen abbilden und dadurch mehr Muster aus den Daten erkennen. Es bedeutet aber auch mehr Gewichte und eine höherer Trainingszeit. Die Layergrösse hat auch Einfluss auf den Bias-Varianz Tradeoff. \n",
    "\n",
    "**Einfluss der Batchgrösse:**  \n",
    "Mit einer kleineren Batchgrösse werden die Gewichte des Modells häufiger angepasst. Das kann das Training schneller aber auch instabiler machen. Eine grössere Batchsize kann eine genauere Schätzung des Gradienten erstellen. Ähnlich wie bei einer tiefen Lernrate, könnten aber lokale Minimas weniger gut übersprungen werden. Die Wahl, spezifisch bei Bilddaten, wird auch stark durch den vorhandenen GPU-Speicher begrenzt. In unseren Versuchen sehen wir ähnliche Ergebnisse in der Test Accuracy wobei die Batchgrössen 16 und 32 die höchste Accuracy erreichten. Interessant war dass das Modell mit der Batchgrösse 4 für 15 Epochen 24 Minuten benötigte, gegenüber von Batchgrösse 16 = 8 Minuten, Batchgrösse 32 = 5 Minuten, Batchgrösse 64 = 4 Minuten und Batchgrösse 128 = 3 Minuten. Die häufige Anpassungen der Gewichte haben deutlichen Einfluss auf die Trainingszeit. Für das Modell soll mit der Batchgrösse 32 fortgefahren werden.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MLP_hl1 Modell Evaluation**:  \n",
    "Für die optimierten Parameter soll das Modell mit 5Fold-Cross-Validation und mit unterschiedlichen Seeds auf Stabilität geprüft werden:\n",
    "\n",
    "*Bemerkung: Die Cross-Validation Option hat einen Fehler der noch nicht behoben ist. CV1 funktioniert, aber für die CV2-5 passen die Train- Testloader nicht überrein und führen zu inkorrekten Losses und Metriken. Dadurch wird die Performance stark überschätzt. Für den Schätzfehler sollen die Modelle zu den unterschiedlichen Seeds betrachtet werden.* \n",
    "\n",
    "<img src=\"../01_Dokumentation/wandb_images/MLP_hl1_5f_cv_seeds.PNG\" width=\"900\" height=\"400\">\n",
    "\n",
    "|Modell| Lernrate | Grösse hL1 | Batchsize | Train Acc | Test Acc | Test Schätzfehler ($\\sigma$) |\n",
    "|----------|----------|----------|----------   |---------- | -------- |-------- |\n",
    "|MLP-hl1-5f-cv (grün)   |1e-2      | 1024     | 32           | 0.6795       | 0.6139       | 0.086      |\n",
    "|MLP-hl1-seeds (gelb)   |1e-2      | 1024     | 32           | 0.5648      | 0.5071       | 0.0088      |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MLP mit 2 hidden Layers**  \n",
    "Ein gängiger Ansatz ist die Grösse der Layer schrittweise zu verringern. In den folgenden Experimenten soll die Lernrate, die Grössen der hidden Layers und die Batchsize untersucht werden:\n",
    "\n",
    "|Experiment| Lernrate | Grösse hL1 | Grösse hL2 |Batchsize |\n",
    "|----------|----------|----------|----------|----------|\n",
    "|1          | 1e-1, 1e-2, 1e-3, 1e-4, 1e-5 | 1024*                       | 256*  | 32*  |\n",
    "|2          | 1e-2**                        | 1024, 2048  |  256*        | 32*        |\n",
    "|3          | 1e-2**                        | 1024**                    | 64, 128, 256, 512  | 32* |\n",
    "|4          | 1e-2**                        | 1024**                    | 512* | 4, 16, 32, 64, 128 |\n",
    "\n",
    "Info:  \n",
    "(\\*) gewählter Startwert    \n",
    "(\\*\\*) optimaler Wert    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPNet_hl2(nn.Module):\n",
    "    def __init__(self, h_layer_sizes:list, input_size=3*32*32, act_fn=F.relu, dropout=0, \n",
    "                init_methode:str='kaiming_norm', output_size=10, bn=False):\n",
    "        super(MLPNet_hl2, self).__init__()\n",
    "        self.bn = bn\n",
    "\n",
    "        self.linear1 = nn.Linear(input_size, h_layer_sizes[0])  # input.shape = (n, 3, 32, 32)\n",
    "        self.bn1 = nn.BatchNorm1d(h_layer_sizes[0])\n",
    "        self.linear2 = nn.Linear(h_layer_sizes[0], h_layer_sizes[1])\n",
    "        self.bn2 = nn.BatchNorm1d(h_layer_sizes[1])\n",
    "        self.linear3 = nn.Linear(h_layer_sizes[1], output_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = act_fn \n",
    "\n",
    "        for linear_weight in [self.linear1.weight, self.linear2.weight]:          \n",
    "            if init_methode == 'uniform':\n",
    "                torch.nn.init.uniform_(linear_weight)\n",
    "            if init_methode == 'xavier':\n",
    "                torch.nn.init.xavier_uniform_(linear_weight)\n",
    "            if init_methode == 'normal':\n",
    "                torch.nn.init.normal_(linear_weight, mean=0, std=1)\n",
    "            if init_methode == 'kaiming_norm':\n",
    "                torch.nn.init.kaiming_normal_(linear_weight, nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x): # x.shape = (n, 3, 32, 32)\n",
    "        x = x.view(-1, 3*32*32) # x.shape = (n, 3072)\n",
    "        x = self.linear1(x)\n",
    "        if self.bn: x = self.bn1(x)\n",
    "        x = self.activation(x) \n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "        if self.bn: x = self.bn2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.linear3(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    from datetime import datetime\n",
    "\n",
    "    # for lr in [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]:\n",
    "    # for hl1_size in [1024, 2048]:\n",
    "    # for hl2_size in [64, 128, 256, 512]:\n",
    "    # for bt_size in [4, 16, 32, 64, 128]:\n",
    "    for seed in [12, 16, 42, 64, 71]:\n",
    "        # Hyperparameters  \n",
    "        config = {\n",
    "            \"name\": \"MLP-hL2\", \n",
    "            \"epochs\": 15,   \n",
    "            \"train_batch_size\": 16, \n",
    "            \"test_batch_size\": 16,\n",
    "            \"dataset\": \"CIFAR-10\",\n",
    "            \"lr\": 1e-2, # default 1e-3\n",
    "            \"optimizer\": 'SGD',\n",
    "            \"Regularisierung\": 'None',  # 'None', 'L1', 'L2',\n",
    "            \"L1_lambda\":0,\n",
    "            \"L2_weight_decay\":0,\n",
    "            \"loss_func\": 'CrossEntropyLoss',\n",
    "            \"loss_func\": 'CrossEntropyLoss',\n",
    "            \"activation\": \"ReLU\",\n",
    "            \"image_size\": 32,\n",
    "            \"cross_validation\": False,\n",
    "            \"n_folds\": 5,\n",
    "            \"is_test_batch\": False,\n",
    "            \"start_time\": datetime.now().strftime(\"%d.%m.%Y_%H%M\"),\n",
    "            \"num_workers\": 0,\n",
    "            \"normalize\":\"zero_one\",\n",
    "            \"init_w_method\":\"kaiming_norm\",  #['uniform', 'xavier', 'normal' ,'kaiming_norm' ]\n",
    "            \"hidden_layer_sizes\": [1024, 512],\n",
    "            \"filter_sizes\": [32, 64],\n",
    "            \"dense_layers\": [512],\n",
    "            \"kernel_sizes\": 3,\n",
    "            \"padding\": 1,\n",
    "            \"stride\": 1,\n",
    "            \"pool_sizes\": [],\n",
    "            \"dropout\": 0,\n",
    "            \"norm_mean\": (0.5, 0.5, 0.5),\n",
    "            \"norm_std\": (0.5, 0.5, 0.5),\n",
    "            \"num_classes\": 10,\n",
    "            \"save_eval_image\": True,\n",
    "            \"set_seed\": seed  # [12, 16, 42, 64, 71]\n",
    "        }\n",
    "\n",
    "        # create model\n",
    "        mlp_h2 = MLPNet_hl2(\n",
    "            h_layer_sizes=config[\"hidden_layer_sizes\"], \n",
    "            act_fn=F.relu,\n",
    "            dropout=0,\n",
    "            init_methode=config[\"init_w_method\"],\n",
    "            )\n",
    "\n",
    "        cv_train_acc_mean, cv_test_acc_mean, _, _ = model_trainer(mlp_h2, config=config,\n",
    "                        group=f'MLP_hL2_seed_val', # _5f_cv, _seed_val, _hl_size{}, _lr{}\n",
    "                        tags=['MLP', 'seed val'], # 5fold cv, seed val, lr\n",
    "                        print_info=False, plot_eval=True, sound=True, \n",
    "                        write_wandb=True\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unterschiedliche Lernraten**\n",
    "\n",
    "<img src=\"../01_Dokumentation/wandb_images/MLP_hl2_lr.PNG\" width=\"900\" height=\"400\">\n",
    "\n",
    "**Unterschiedliche Layergrössen Layer 1**\n",
    "\n",
    "<img src=\"../01_Dokumentation/wandb_images/MLP_hl2_layer1_size.PNG\" width=\"900\" height=\"400\">\n",
    "\n",
    "**Unterschiedliche Layergrössen Layer 2**\n",
    "\n",
    "<img src=\"../01_Dokumentation/wandb_images/MLP_hl2_layer2_size.PNG\" width=\"900\" height=\"400\">\n",
    "\n",
    "**Unterschiedliche Batchgrösse**\n",
    "\n",
    "<img src=\"../01_Dokumentation/wandb_images/MLP_hl2_batch_size.PNG\" width=\"900\" height=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "**Einfluss der Learningrate:**  \n",
    " Auch hier verzeichnet die Lernrate einen grossen Einfluss auf das Training. Lernraten von $1^{-5}$ oder $1^{-4}$ führen zu einem deutlich langsameren Training. Die lr von $1^{-2}$ erziehlte aus meiner Sicht das beste Ergebnis. Tiefere Training- und Validationslosses und die Accuracy schwankt ein wenig, aber es deutet noch kein Overfitting an.    \n",
    "\n",
    "\n",
    "**Einfluss Grösse des Hidden Layers:**   \n",
    "Das Modell umfasst nun zwei hidden Layer. Für den ersten Layer wurden zwei Grössen auspobiert 1024 und 2048. Beide Trainings führen zu sehr ähnlichen Ergebnissen im Loss und der Accuracy. Um einem Overfitting vorzubeugen wird die Layergrösse 1024 verwendet. Für den zweiten Layer wurden die Grössen 64, 128, 256, 512 ausprobiert. Die Grösse 512 erziehlte eine leicht höhere Accuracy und könnte mit einem längerem Training (mehr Epochen) evtl. das Modell weiter verbessern.\n",
    "\n",
    "**Einfluss der Batchsize:**  \n",
    "Die Batchgrösse sollte Einfluss auf die Stabilität des Trainings haben. Interessant ist, dass mit Batchsize 4 und 128 die Accuracy und der Validation Loss keine grossen Schwankungen zeigen. Bei Batchsize 4 wäre eine grössere Instabiltät erwartet worden. Batchsize 16 bietet die beste Accuracy bei einem stabilen Anstieg und den tiefesten Validationloss. Best Epoch wird bereits bei 10 gemessen was auf ein frühes Zeichen von Overfitting sein könnte. Deutlich spürbar war die Wahl der Batchsize bei der Dauer des Modelltrainings: Batchsize 4 dauerte 25 Minuten, Batchsize 16, 32, 64, 128 führten zu 9, 5, 4, 3 Minuten.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MLP_hl2 Modell Evaluation**:  \n",
    "Für die optimierten Parameter soll das Modell mit 5Fold-Cross-Validation und mit unterschiedlichen Seeds geprüft werden:  \n",
    "\n",
    "*Bemerkung: Die Cross-Validation Option hat einen Fehler der noch nicht behoben ist. CV1 funktioniert, aber für die CV2-5 passen die Train- Testloader nicht überrein und führen zu inkorrekten Losses und Metriken. Dadurch wird die Performance stark überschätzt. Für den Schätzfehler sollen die Modelle zu den unterschiedlichen Seeds betrachtet werden.* \n",
    "\n",
    "<img src=\"../01_Dokumentation/wandb_images/MLP_hl2_5f_cv_seeds.PNG\" width=\"900\" height=\"400\">\n",
    "\n",
    "|Modell| Lernrate | Grösse hL1 | Grösse hL1 |Batchsize | Train Acc | Test Acc | Test Schätzfehler ($\\sigma$) |\n",
    "|------|----------|----------   |---------- |---------- |---------- | -------- |--------                    |\n",
    "|MLP-hl2-5f-cv (--)   |1e-2      | 1024     | 512      | 16           | 0.8208       | 0.7026       | 0.1646      |\n",
    "|MLP-hl2-seeds (-)   |1e-2      | 1024     | 512      | 16           | 0.6124      | 0.5310       | 0.0070      |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CNN** Hyperparameter Suche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folgende wird ein einfaches CNN Modell erstellt. Es soll den Einfluss von verschiedenen Lernraten, Batchsize, Anzahl Filtern, Kernel-Grössen, Strides und Paddings untersucht werden:\n",
    "\n",
    "**Ablauf:**  \n",
    "1. verschiedene Lernraten werden untersucht\n",
    "1. verschiedene Anzahl Filter werden untersucht\n",
    "1. verschiedene Batchgrössen werden untersucht\n",
    "1. verschiedene Kernelgrössen, Strides und Padding werden untersucht\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple CNN**  \n",
    "\n",
    "|Experiment| Lernrate | Grösse Filter1 |  Grösse Filter2 |Batchsize |Kernel-Grösse | Stride | Padding |\n",
    "|---|----------|----------|----------|----------|----------|----------|----------|\n",
    "|1| 1e-1, 1e-2, 1e-3, 1e-4, 1e-5 | 32*  | 64*  | 32*  | 3*  | 1*  | 1*  |\n",
    "|2| 1e-2** | 16, 32, 64 | 64* |  32* | 3*  | 1*  | 1*  |\n",
    "|3| 1e-2** | 32**  | 32, 64, 96  | 32*  | 3*  | 1*  | 1*  |\n",
    "|4| 1e-2** | 32**  | 64**  | 8, 16, 32, 64  | 3*  | 1*  | 1*  |\n",
    "|5| 1e-2** | 32**  | 64**  | 32**  | 3, 5, 7  | 1*  | 1*  |\n",
    "|6| 1e-2** | 32**  | 64**  | 32**  | 3** | 1, 2, 3  | 1*  |\n",
    "|7| 1e-2** | 32**  | 64**  | 32**  | 3** | 1**  | 0, 1, 2  |\n",
    "\n",
    "Info:  \n",
    "(\\*) gewählter Startwert    \n",
    "(\\*\\*) optimaler Wert    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionsberechnungen für Covolution Layers:  \n",
    "Um die CNN Klasse variable zu gestalten, müssen die Dimensionen anhand der Hyperparameter berechnet werden\n",
    "$$Output\\ Grösse = \\frac{Input\\ Grösse + (2 \\cdot padding - Kernel\\ Grösse)}{stride} + 1 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_conv_dim(input_size, kernel_size, padding, stride, pooling=True):\n",
    "    conv_dim = int((input_size + 2 * padding - kernel_size) / stride + 1)\n",
    "\n",
    "    if pooling: conv_dim = conv_dim / 2\n",
    "    return conv_dim\n",
    "\n",
    "# Berechnungstest\n",
    "input_dim_bild = 32  # 32x32 pixel cifar-10\n",
    "kernel_size = 3  # 3x3\n",
    "padding = 1\n",
    "stride = 1\n",
    "conv2_out_channel = 64\n",
    "\n",
    "print(f'{input_dim_bild=}')  \n",
    "output_dim_conv1 = compute_conv_dim(input_dim_bild, kernel_size, padding, stride, pooling=True)\n",
    "print(f'{output_dim_conv1=}') \n",
    "\n",
    "output_dim_conv2 = compute_conv_dim(output_dim_conv1, kernel_size, padding, stride, pooling=True)\n",
    "print(f'{output_dim_conv2=}') \n",
    "\n",
    "input_fc1 = output_dim_conv2 * output_dim_conv2 * conv2_out_channel\n",
    "print(f'{input_fc1=} = {output_dim_conv2} x {output_dim_conv2} x {conv2_out_channel}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell Class\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, input_ch=3, act_fn=F.relu, filter_size:list=[32, 64], dlayers:list=[512], num_class=10,\n",
    "                kernel_size=3, padding=1, stride=1, dropout_ch=0, bn=False, reg='L1', input_image=32):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.bn = bn\n",
    "        self.reg = reg\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=input_ch, out_channels=filter_size[0], \n",
    "                            kernel_size=kernel_size, padding=padding, stride=stride)\n",
    "        self.conv2 = nn.Conv2d(in_channels=filter_size[0], out_channels=filter_size[1], \n",
    "                            kernel_size=kernel_size, padding=padding, stride=stride)      \n",
    "                \n",
    "        self.dim1 = self.compute_conv_dim(input_image, kernel_size, padding, stride)\n",
    "        self.dim2 = self.compute_conv_dim(self.dim1, kernel_size, padding, stride)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.dim2 * self.dim2 * filter_size[1], dlayers[0])\n",
    "        self.fc2 = nn.Linear(dlayers[0], num_class)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.activation = act_fn \n",
    "\n",
    "        # Dropout for convolution layers\n",
    "        self.dropout2D = nn.Dropout2d(dropout_ch)\n",
    "        # Dropout for dense layers\n",
    "        self.dropout = nn.Dropout(dropout_ch)\n",
    "\n",
    "        # Batch normalization layers for convolution layers\n",
    "        self.bn1 = nn.BatchNorm2d(filter_size[0])\n",
    "        self.bn2 = nn.BatchNorm2d(filter_size[1])\n",
    "        \n",
    "        # Batch normalization layer for dense layer\n",
    "        self.bn_fc1 = nn.BatchNorm1d(dlayers[0])\n",
    "        self.dim = []\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_conv_dim(input_size, kernel_size, padding, stride, pooling=True):\n",
    "        conv_dim = int((input_size + 2 * padding - kernel_size) / stride + 1)\n",
    "        if pooling: conv_dim = int(conv_dim / 2)\n",
    "        return conv_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        if self.bn: x = self.bn1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        if self.bn: x = self.bn2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        if self.bn: x = self.bn_fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    from datetime import datetime\n",
    "\n",
    "    # for lr in [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]: \n",
    "    # for f1_size in [16, 32, 64]:\n",
    "    # for f2_size in [32, 64, 96]:\n",
    "    # for bt_size in [8, 16, 32, 64]:\n",
    "    # for kernel_size in [3, 5, 7]:\n",
    "    # for stride in [1, 2, 3]:\n",
    "    # for padding in [0, 1, 2]:  \n",
    "    for seed in [12, 16, 42, 64, 71]:\n",
    "        # Hyperparameters  \n",
    "        config = {\n",
    "            \"name\": \"CNN-simple\", \n",
    "            \"epochs\": 20,   \n",
    "            \"train_batch_size\": 32, \n",
    "            \"test_batch_size\": 32,\n",
    "            \"dataset\": \"CIFAR-10\",\n",
    "            \"lr\": 1e-2, # default 1e-3\n",
    "            \"optimizer\": 'SGD',\n",
    "            \"Regularisierung\": 'None',  # 'None', 'L1', 'L2',\n",
    "            \"L1_lambda\":0,\n",
    "            \"L2_weight_decay\":0,\n",
    "            \"loss_func\": 'CrossEntropyLoss',\n",
    "            \"activation\": \"ReLU\",\n",
    "            \"image_size\": 32,\n",
    "            \"cross_validation\": False,\n",
    "            \"n_folds\": 5,\n",
    "            \"is_test_batch\": False,\n",
    "            \"start_time\": datetime.now().strftime(\"%d.%m.%Y_%H%M\"),\n",
    "            \"num_workers\": 0,\n",
    "            \"normalize\":\"zero_one\",\n",
    "            \"init_w_method\":\"kaiming_norm\",  #['uniform', 'xavier', 'normal' ,'kaiming_norm' ]\n",
    "            \"hidden_layer_sizes\": [1024, 256],\n",
    "            \"filter_sizes\": [32, 64],\n",
    "            \"dense_layers\": [512],\n",
    "            \"kernel_sizes\": 3,\n",
    "            \"padding\": 2,\n",
    "            \"stride\": 1,\n",
    "            \"pool_sizes\": [],\n",
    "            \"dropout\": 0,\n",
    "            \"norm_mean\": (0.5, 0.5, 0.5),\n",
    "            \"norm_std\": (0.5, 0.5, 0.5),\n",
    "            \"num_classes\": 10,\n",
    "            \"save_eval_image\": True,\n",
    "            \"set_seed\": seed  # [12, 16, 42, 64, 71]\n",
    "        }\n",
    "\n",
    "        # create model\n",
    "        cnn_simple = SimpleCNN(\n",
    "            filter_size=config[\"filter_sizes\"],\n",
    "            dlayers=config[\"dense_layers\"],\n",
    "            act_fn=F.relu,\n",
    "            kernel_size=config[\"kernel_sizes\"],\n",
    "            padding=config[\"padding\"],\n",
    "            stride=config[\"stride\"],\n",
    "            dropout_ch=0,\n",
    "            )\n",
    "\n",
    "        cv_train_acc_mean, cv_test_acc_mean, _, _ = model_trainer(cnn_simple, config=config,\n",
    "                        group=f'CNN_simple_seed_val', # _5f_cv, _seed_val, _hl_size{}, _lr{}\n",
    "                        tags=['CNN', 'seed val'], # 5fold cv, seed val, lr\n",
    "                        print_info=False, plot_eval=True, sound=True, \n",
    "                        write_wandb=True\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unterschiedliche Lernrate**\n",
    "\n",
    "<img src=\"../01_Dokumentation/wandb_images/CNN_simple_lr.PNG\" width=\"900\" height=\"400\">\n",
    "\n",
    "**Unterschiedliche Anzahl Filter**\n",
    "\n",
    "<img src=\"../01_Dokumentation/wandb_images/CNN_simple_num_filters.PNG\" width=\"900\" height=\"400\">\n",
    "\n",
    "**Unterschiedliche Batchgrössen**\n",
    "\n",
    "<img src=\"../01_Dokumentation/wandb_images/CNN_simple_bt_sizes.PNG\" width=\"900\" height=\"400\">\n",
    "\n",
    "**Unterschiedliche Kernel Grössen**\n",
    "\n",
    "<img src=\"../01_Dokumentation/wandb_images/CNN_simple_kernel_sizes.PNG\" width=\"900\" height=\"400\">\n",
    "\n",
    "**Unterschiedliche Strides und Paddings**\n",
    "\n",
    "<img src=\"../01_Dokumentation/wandb_images/CNN_simple_strides_paddings.PNG\" width=\"900\" height=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "**Einfluss der Learningrate:**  \n",
    "Um die Unterschiede der Lernraten besser zu zeigen wurden Modelle für 20 Epochen trainiert. Die Lernraten $1^{-5}$ und $1^{-4}$ sind zu tief und führen zu keinem Training. Die Lernraten $1^{-1}$ und $1^{-2}$ führen zu einer sehr ähnlichen Test Accuracy, wobei der Trainingsprozess sehr verschieden ist. Mit lr $1^{-1}$ steigt der Validationloss ab Epoche 4 stark an, auch die Trainings Accuracy ist sehr hoch. Das Modell trainiert sehr schnell und sollte nach ein paar Epochen beendet werden. Die lr $1^{-2}$ wurde ausgewählt da sie einen stabileren Eindruck vermittelt.\n",
    "\n",
    "\n",
    "**Einfluss der Filter Grösse:**   \n",
    "Mit mehr Filter können mehr Merkmale erkannt und komplexere Aufgaben gelöst werden. Für die 32x32 Bilder von Cifar-10 wurde eine unterschiedliche Anzahl von Filtern getestet. Für den ersten CNN-Layer wurden die Filtergrösse 16, 32, 64 auspobiert, für den zweiten Layer die Grössen 32, 64, 96. Anhand der Accuracy und der Losswerten konnte keinen markanten Einfluss auf die Modelloptimerung festgestellt werden. Für das weitere Training wurden die Grössen 32 und 64 für die beiden Layer verwendet. Auf die Trainingszeiten hatte die Filtergrösse auch keinen Einfluss. Bei klompexeren Daten/Aufgaben und mehr CNN-Layer, könnte es sich evtl. dennoch lohnen die Filtergrösse zu untersuchen.\n",
    "\n",
    "\n",
    "**Einfluss der Batchgrössen:**  \n",
    "Die Batchgrösse hängt auch stark vom GPU-Speicher ab, eine RTX-2070 GPU mit 8GB war bei einer Batchsize von 64 zu 70% ausgelastet.\n",
    "Ähnliche Erkentnisse wie bei den MLP Modellen sehen wir verstärkt für die CNN Modelle. Mit einer Batchsize von 8 kann das Training viel früher gestoppt werden. Auch hier verzeichnet eine tiefe Batchsize eine lange Trainingsdauer für 20 Epochen. Da das Training aber viel schneller lernt, werden keine 20 Epochen benötigt. Für mehr Stabilität wurde dennoch eine Batchsize von 16 gewählt. Hier können später auch die Regularisierungs Methoden gut ausprobiert werden.\n",
    "\n",
    "\n",
    "**Einfluss der Kernel Grösse:**  \n",
    "Kleiner Kernel von 1x1 oder 3x3 sind besser geeignet um lokale Informationen zu erfassen, Kernel mit 5x5 und 7x7 fangen eher globale Muster auf. Die Kernel Grössen 3,5,7 wurden ausprobiert. Auf die Bilder von Cifar-10 konnte keinen wesentlichen Einfluss bemerkt werden. Der Validationloss für die Grössen 5,7 ist gegen Ende höher, was auf eine schnelleres Overfitting durch mehr globale Informationen hindeuten könnte. \n",
    "\n",
    "\n",
    "**Einfluss von Stride und Padding:**  \n",
    "**Stride** bezeichnet die Schrittweite, mit der der Kernel über das Bild fährt. Bei einem Wert von 1 überlappt sich der Filter, bei grösseren Werten kann das Netzwerk schneller grössere Muster erkennen. Ein hoher Stride kann auch als Pooling Ersatz dienen, also die Bilddimension reduzieren. Bisher habe ich in Modellen nur Stridewerte von 1 gesehen, darum soll hier untersucht werden welchen Einfluss von grösseren Werten erkennbar ist. Ein Stridewert von 1 zeigte deutlich bessere Modell Performance. Dadurch dass die 32x32 Bilder nicht sehr gross sind, werden wohl eher kleine Muster benötigt. Interessant wäre es, den Pooling Layer durch einen höheren Stride zu ersetzen.   \n",
    "**Padding** fügt rund um das Bild weitere Pixel hinzu (mit Pytorch default Pixelwert ist 0 - Zero Padding), dies kann verwendet werden um die Bilddimension nach einer Convolution beizubehalten. Bei einem Padding > 0 kann zudem der ganze Filter auch am Rand des Bilder angewendet werden und Muster erkennen. Es wurde Padding zu den Werten 0, 1, 2 untersucht (Kernelgrösse bei 3x3 festgelegt, dadurch Padding bei max 2). Nicht sehr markant aber das Training und die Accuracy profitieren von Padding = 2. Zu beachten ist, dass die Objekte in den Bildern wohl eher zentriert sind.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN Modell Evaluation**:  \n",
    "Für die optimierten Parameter soll das Modell mit 5Fold-Cross-Validation und mit unterschiedlichen Seeds geprüft werden:\n",
    "\n",
    "*Bemerkung: Die Cross-Validation Option hat einen Fehler der noch nicht behoben ist. CV1 funktioniert, aber für die CV2-5 passen die Train- Testloader nicht überrein und führen zu inkorrekten Losses und Metriken. Dadurch wird die Performance stark überschätzt. Für den Schätzfehler sollen die Modelle zu den unterschiedlichen Seeds betrachtet werden.* \n",
    "\n",
    "<img src=\"../01_Dokumentation/wandb_images/CNN_simple_5f_cv_seeds.PNG\" width=\"900\" height=\"400\">\n",
    "\n",
    "|Modell| Lernrate | Grösse Filter1 | Grösse Filter2 |Batchsize | Kernel, Stride, Padding |Train Acc | Test Acc | Test Schätzfehler ($\\sigma$) |\n",
    "|------|----------|----------   |---------- |---------- |---------- | --------          |--------        |--------                    |\n",
    "|CNN-simple-5f-cv   |1e-2      | 32     | 64      | 32      |  3,1,2    | 0.9671       | 0.8978       | 0.139      |\n",
    "|CNN-simple-seeds   |1e-2      | 32     | 64      | 32      |  3,1,2    | 0.8453      | 0.6900       | 0.009      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "### Fazit Modelkomplexität\n",
    "Die CNN Modelle sind den MLP Modellen überlegen. Die spezielle Verarbeitung mit den Convolutions kann Bilder besser verarbeiten und lokale Muster besser erkennen.\n",
    "\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**2. Nutzen der Regularisierung**  \n",
    "Ziehe nun verschiedene Regularisierungsmethoden bei den MLP Layern in Betracht:  \n",
    "a. L1/L2 Weight Penalty  \n",
    "b. Dropout\n",
    "\n",
    "Evaluiere den Nutzen der Regularisierung, auch unter Berücksichtigung verschiedener Regularisierungsstärken. Beschreibe auch kurz, was allgemein das Ziel von Regularisierungsmethoden ist (Regularisierung im Allgemeinen, sowie auch Idee der einzelnen Methoden). Inwiefern wird dieses Ziel im gegebenen Fall erreicht?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Das allgemeine Ziel der Regularisierung ist eine Generalisierung des Modells. Spezfische Deep Learning ist vom Overfitting Problem betroffen, die Regularisierung schränkt die Komplexität des Modells und soll ein OVerfitting eingrenzen/verhindern.\n",
    "\n",
    "**L1**  \n",
    "Die Lasso-Regularisierung fügt der Lossfunktion die absolute Summe der Gewichte hinzu. Der $ \\lambda$-Wert  ist der Regularisierungskoeffizient. Mit L1 werden die Gewichte eher auf Null gesetzt, was idealer Weise weniger relevante Merkmale gleich entfernt.\n",
    "\n",
    "**L2**  \n",
    "Die Ridge-Regularisierung lässt die Gewichte während dem Training schrumpfen. Die quadrierten Gewichtswerte werden mit 'weight-decay' skalliert und zur Lossfunktion hinzugefügt. In Pytorch steht dafür der Hyperparameter 'weight-decay' zur Verfügung. Bei jeder Epoche werden die Gewichte tendenziell gegen 0 gezogen.\n",
    "\n",
    "**Dropout**  \n",
    "**MLP**: Bei jedem Trainingsschritt werden zufällig Neuronen deaktiviert (einzelne Elemente in einem Tensor). Das Netzwerk kann sich so nicht auf einzelnen Neuronen verlassen.  \n",
    "**CNN**: Bei Dropout_2D werden ganze Känale oder Feature-Maps deaktiviert. Das Netzwerk kann sich so nicht auf einzelne Features verlassen.\n",
    "\n",
    "**Early Stopping**  \n",
    "Das Modelltraining wird beendet sobald die Performance auf dem Validierungsdatensatz nicht verbessert werden kann. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MLP** Regularisierung\n",
    "\n",
    "Folgende wird zum MLP Modell mit 2 Hidden Layers den Einsatz von Regularisierungen getestet. Es soll der Einfluss der `L1`, `L2` Regularisierung sowie von `Dropout` untersucht werden.\n",
    "\n",
    "**Ablauf:**  \n",
    "1. Modell ohne Regularisierung mit längerer Trainingsdauer\n",
    "1. L1-Regularisierung zu verschiedenen L1-Lambda Werten\n",
    "1. L2-Regularisierung zu verschiedenen Weight-Decay Werten\n",
    "1. Dropout mit verschiedenen Wahrscheinlichkeiten\n",
    "\n",
    "\n",
    "|Experiment| L1-Lambda | L2-Weight Decay |  Dropout  \n",
    "|---|----------|----------|----------|\n",
    "|1| 0| 0  | 0  |\n",
    "|2| 1e-5, 1e-4  | 0  | 0 | \n",
    "|3| 0 | 1e-4, 1e-3, 1e-2|  0 | \n",
    "|4| 0 | 0 | 0.2, 0.4, 0.6, 0.8  | \n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    from datetime import datetime\n",
    "\n",
    "    # for no_reg in [1]:\n",
    "    # for L1_lambda in [1e-5, 1e-4]:  \n",
    "    # for L2_w_decay in [1e-4, 1e-3, 1e-2]:\n",
    "    for dropout_p in [0.2, 0.4, 0.6, 0.8]:\n",
    "        # Hyperparameters  \n",
    "        config = {\n",
    "            \"name\": \"MLP-hL2\", \n",
    "            \"epochs\": 25,   \n",
    "            \"train_batch_size\": 16, \n",
    "            \"test_batch_size\": 16,\n",
    "            \"dataset\": \"CIFAR-10\",\n",
    "            \"lr\": 1e-2, # default 1e-3\n",
    "            \"optimizer\": 'SGD',\n",
    "            \"Regularisierung\": 'None',  # 'None', 'L1', 'L2',\n",
    "            \"L1_lambda\": 0,\n",
    "            \"L2_weight_decay\": 0,\n",
    "            \"loss_func\": 'CrossEntropyLoss',\n",
    "            \"loss_func\": 'CrossEntropyLoss',\n",
    "            \"activation\": \"ReLU\",\n",
    "            \"image_size\": 32,\n",
    "            \"cross_validation\": False,\n",
    "            \"n_folds\": 5,\n",
    "            \"is_test_batch\": False,\n",
    "            \"start_time\": datetime.now().strftime(\"%d.%m.%Y_%H%M\"),\n",
    "            \"num_workers\": 0,\n",
    "            \"normalize\":\"zero_one\",\n",
    "            \"init_w_method\":\"kaiming_norm\",  #['uniform', 'xavier', 'normal' ,'kaiming_norm' ]\n",
    "            \"hidden_layer_sizes\": [1024, 512],\n",
    "            \"filter_sizes\": [32, 64],\n",
    "            \"dense_layers\": [512],\n",
    "            \"kernel_sizes\": 3,\n",
    "            \"padding\": 1,\n",
    "            \"stride\": 1,\n",
    "            \"pool_sizes\": [],\n",
    "            \"dropout\": dropout_p,\n",
    "            \"norm_mean\": (0.5, 0.5, 0.5),\n",
    "            \"norm_std\": (0.5, 0.5, 0.5),\n",
    "            \"num_classes\": 10,\n",
    "            \"save_eval_image\": True,\n",
    "            \"set_seed\": 42 \n",
    "        }\n",
    "\n",
    "        # create model\n",
    "        mlp_h2 = MLPNet_hl2(\n",
    "            h_layer_sizes=config[\"hidden_layer_sizes\"], \n",
    "            act_fn=F.relu,\n",
    "            dropout=config['dropout'],\n",
    "            init_methode=config[\"init_w_method\"],\n",
    "            )\n",
    "\n",
    "        cv_train_acc_mean, cv_test_acc_mean, _, _ = model_trainer(mlp_h2, config=config,\n",
    "                        group=f'MLP_hL2_drop_{dropout_p}', # _5f_cv, _seed_val, _hl_size{}, _lr{}\n",
    "                        tags=['MLP', 'dropout'], # 5fold cv, seed val, lr\n",
    "                        print_info=False, plot_eval=True, sound=True, \n",
    "                        write_wandb=True\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unterschiedliche L1-Lambda Werte**\n",
    "\n",
    "<img src=\"../01_Dokumentation/wandb_images/MLP_hl2_reg_l1.PNG\" width=\"900\" height=\"400\">\n",
    "\n",
    "**Unterschiedliche L2-Weight Decay Werte**\n",
    "\n",
    "<img src=\"../01_Dokumentation/wandb_images/MLP_hl2_reg_L2.PNG\" width=\"900\" height=\"400\">\n",
    "\n",
    "**Unterschiedliche Dropout**\n",
    "\n",
    "<img src=\"../01_Dokumentation/wandb_images/MLP_hl2_reg_dropout.PNG\" width=\"900\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "**Unterschiedliche L1-Lambda Werte**  \n",
    "Verglichen wurde das MLP mit zwei hidden Layer ohne und mit Regularisierung zu unterschiedlichen $\\lambda$-Werten. Bei $\\lambda=1^{-5}$ noch wenig dann bei $\\lambda=1^{-4}$ wird das Training erheblich beeinflusst. Ohne Regularisierung findet ein Overfitting ab Epoche 16 statt. Der Einfluss von L1 kann vor allem im Trainingsloss und der Trainings Accuracy gesehen werden. Das Modell mit $\\lambda=1^{-4}$ zeigt eine tiefere Test Accuracy, aber dafür ist sie näher an der Training Accurcy, was eher für ein generalisiertes Modell steht. Um Trainingszeit zu sparen, würde das Einsetzen von 'early-stopping' auch Sinn machen.\n",
    "\n",
    "**Unterschiedliche L2-Weight Decay Werte**   \n",
    "Der Wert $1^{-2}$ Regularisiert das Modell zu stark. Der Wert $1^{-3}$ beeinflusst die Test Accuracy nur sehr wenig, reguliert aber den Trainingsloss und die Trainings Accuracy. Auch hier würde wohl 'early-stopping' einen ähnlichen Effekt erzielen können.\n",
    "\n",
    "**Unterschiedliche Dropout**  \n",
    "Verschiedene Dropout Wahrscheinlichkeiten wurden getestet, 0.2, 0.4, 0.6 und 0.8. Auch hier gut ersichtlich den Einfluss auf die Trainings Accuracy. Ein nutzvoller Wert scheint bei $dropout=0.4$ zu liegen.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CNN** Regularisierung\n",
    "\n",
    "Folgende wird zum CNN simple Modell den Einsatz von Regularisierungen getestet. Es soll der Einfluss der `L1`, `L2` Regularisierung sowie von `Dropout` untersucht werden.\n",
    "\n",
    "**Ablauf:**  \n",
    "1. Modell ohne Regularisierung mit längerer Trainingsdauer\n",
    "1. L1-Regularisierung zu verschiedenen L1-Lambda Werten\n",
    "1. L2-Regularisierung zu verschiedenen Weight-Decay Werten\n",
    "1. Dropout mit verschiedenen Wahrscheinlichkeiten\n",
    "\n",
    "\n",
    "|Experiment| L1-Lambda | L2-Weight Decay |  Dropout |\n",
    "|---|----------|----------|----------|\n",
    "|1| 0| 0  | 0  | \n",
    "|2| 1e-5, 1e-4 | 0  | 0 \n",
    "|3| 0 | 1e-5, 1e-4, 1e-3, 1e-2|  0 \n",
    "|4| 0 | 0  | 0.2, 0.4, 0.6  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    from datetime import datetime\n",
    "\n",
    "    # for no_reg in [1]:\n",
    "    # for L1_lambda in [1e-5, 1e-4, 1e-3]:\n",
    "    # for L2_w_decay in [1e-4, 1e-3, 1e-2]:\n",
    "    for dropout_p in [0.2, 0.4, 0.6, 0.8]:\n",
    "        # Hyperparameters  \n",
    "        config = {\n",
    "            \"name\": \"CNN-simple\", \n",
    "            \"epochs\": 30,   \n",
    "            \"train_batch_size\": 32, \n",
    "            \"test_batch_size\": 32,\n",
    "            \"dataset\": \"CIFAR-10\",\n",
    "            \"lr\": 1e-2, # default 1e-3\n",
    "            \"optimizer\": 'SGD',\n",
    "            \"Regularisierung\": 'None',  # 'None', 'L1', 'L2',\n",
    "            \"L1_lambda\":0,\n",
    "            \"L2_weight_decay\":0,\n",
    "            \"loss_func\": 'CrossEntropyLoss',\n",
    "            \"activation\": \"ReLU\",\n",
    "            \"image_size\": 32,\n",
    "            \"cross_validation\": False,\n",
    "            \"n_folds\": 5,\n",
    "            \"is_test_batch\": False,\n",
    "            \"start_time\": datetime.now().strftime(\"%d.%m.%Y_%H%M\"),\n",
    "            \"num_workers\": 0,\n",
    "            \"normalize\":\"zero_one\",\n",
    "            \"init_w_method\":\"kaiming_norm\",  #['uniform', 'xavier', 'normal' ,'kaiming_norm' ]\n",
    "            \"hidden_layer_sizes\": [1024, 256],\n",
    "            \"filter_sizes\": [32, 64],\n",
    "            \"dense_layers\": [512],\n",
    "            \"kernel_sizes\": 3,\n",
    "            \"padding\": 2,\n",
    "            \"stride\": 1,\n",
    "            \"pool_sizes\": [],\n",
    "            \"dropout\": dropout_p,\n",
    "            \"norm_mean\": (0.5, 0.5, 0.5),\n",
    "            \"norm_std\": (0.5, 0.5, 0.5),\n",
    "            \"num_classes\": 10,\n",
    "            \"save_eval_image\": True,\n",
    "            \"set_seed\": 42  # [12, 16, 42, 64, 71]\n",
    "        }\n",
    "\n",
    "        # create model\n",
    "        cnn_simple = SimpleCNN(\n",
    "            filter_size=config[\"filter_sizes\"],\n",
    "            dlayers=config[\"dense_layers\"],\n",
    "            act_fn=F.relu,\n",
    "            kernel_size=config[\"kernel_sizes\"],\n",
    "            padding=config[\"padding\"],\n",
    "            stride=config[\"stride\"],\n",
    "            dropout_ch=config[\"dropout\"],\n",
    "            )\n",
    "\n",
    "        cv_train_acc_mean, cv_test_acc_mean, _, _ = model_trainer(cnn_simple, config=config,\n",
    "                        group=f'CNN_simple_drop_{dropout_p}', # _5f_cv, _seed_val, _hl_size{}, _lr{}\n",
    "                        tags=['CNN', 'dropout reg'], # 5fold cv, seed val, lr\n",
    "                        print_info=False, plot_eval=True, sound=True, \n",
    "                        write_wandb=True\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unterschiedliche L1-Lambda Werte**\n",
    "\n",
    "<img src=\"../01_Dokumentation/wandb_images/CNN_simple_reg_L1.PNG\" width=\"900\" height=\"400\">\n",
    "\n",
    "**Unterschiedliche L2-Weight Decay Werte**\n",
    "\n",
    "<img src=\"../01_Dokumentation/wandb_images/CNN_simple_reg_L2.PNG\" width=\"900\" height=\"400\">\n",
    "\n",
    "**Unterschiedliche Dropout**\n",
    "\n",
    "<img src=\"../01_Dokumentation/wandb_images/CNN_simple_reg_dropout.PNG\" width=\"900\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "**Unterschiedliche L1-Lambda Werte**  \n",
    "Der $\\lambda$-Wert für L1 ist auch hier sehr empfindlich und muss sorgfälltig gewählt werden. Neben einer Regularisierung von $\\lambda=1^{-4}$ könnte zusätzlich auch 'early stopping' vewendet werden.\n",
    "\n",
    "**Unterschiedliche L2-Weight Decay Werte**  \n",
    "Ein optimaler Wert scheint sich um $1^{-2}$ herum zu finden.\n",
    "\n",
    "**Unterschiedliche Dropout Wahrscheinlichkeit**  \n",
    "Verschiedene Dropout Wahrscheinlichkeiten wurden getestet, 0.2, 0.4, 0.6 und 0.8. Auch hier gut ersichtlich den Einfluss auf die Trainings Accuracy. Ein nutzvoller Wert scheint hier bei $dropout=0.3$ zu liegen.  \n",
    "*Bemerkung: Der Dropout Parameter setzt die dropout sowie droupout_2d Rate*\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**3. Nutzen von Batchnorm BN (ohne REG, mit SGD)**  \n",
    "Evaluiere, ob Batchnorm etwas bringt. Beschreibe kurz, was die Idee von BN ist, wozu es helfen soll.\n",
    "    \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Batch Normalization (BN) ermöglicht ein schnelleres und stabileres Training von tiefen Netzwerken. Die Aktivierung innerhalb eines Batches haben so den Mittelwert 0 und eine Standardabweichung von 1. Während dem Training verschieben sich normalerweise die Verteilungen der Aktivierungen, BN soll das verhindern. BN macht das Netzwerk auch weniger empfindlich gegenüber der Initialisierung der Gewichte und hat leichte regularisierende Effekte.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MLP** und **CNN** Batchnorm\n",
    "\n",
    "Folgend wird zum MLP und CNN Modell den Einsatz von Batchnormalisierung getestet. \n",
    "\n",
    "**Ablauf:**  \n",
    "1. Modelle ohne Batchnormalisierung \n",
    "1. Modelle mit Batchnormalisierung \n",
    "\n",
    "\n",
    "|Modell| Batchnorm |\n",
    "|---|----------|\n",
    "|MLP-h2l| Aus| \n",
    "|MLP-h2l|  Ein | \n",
    "|CNN-simple| Aus | \n",
    "|CNN-simple| Ein | \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "if False:\n",
    "    from datetime import datetime\n",
    "\n",
    "    for bn in [False, True]:\n",
    "        # Hyperparameters  \n",
    "        config = {\n",
    "            \"name\": \"MLP-hL2\", \n",
    "            \"epochs\": 25,   \n",
    "            \"train_batch_size\": 16, \n",
    "            \"test_batch_size\": 16,\n",
    "            \"dataset\": \"CIFAR-10\",\n",
    "            \"lr\": 1e-2, # default 1e-3\n",
    "            \"optimizer\": 'SGD',\n",
    "            \"Regularisierung\": 'None',  # 'None', 'L1', 'L2',\n",
    "            \"L1_lambda\": 0,\n",
    "            \"L2_weight_decay\": 0,\n",
    "            \"batchnorm\": bn,\n",
    "            \"loss_func\": 'CrossEntropyLoss',\n",
    "            \"loss_func\": 'CrossEntropyLoss',\n",
    "            \"activation\": \"ReLU\",\n",
    "            \"image_size\": 32,\n",
    "            \"cross_validation\": False,\n",
    "            \"n_folds\": 5,\n",
    "            \"is_test_batch\": False,\n",
    "            \"start_time\": datetime.now().strftime(\"%d.%m.%Y_%H%M\"),\n",
    "            \"num_workers\": 0,\n",
    "            \"normalize\":\"zero_one\",\n",
    "            \"init_w_method\":\"kaiming_norm\",  #['uniform', 'xavier', 'normal' ,'kaiming_norm']\n",
    "            \"hidden_layer_sizes\": [1024, 512],\n",
    "            \"filter_sizes\": [32, 64],\n",
    "            \"dense_layers\": [512],\n",
    "            \"kernel_sizes\": 3,\n",
    "            \"padding\": 1,\n",
    "            \"stride\": 1,\n",
    "            \"pool_sizes\": [],\n",
    "            \"dropout\": 0,\n",
    "            \"norm_mean\": (0.5, 0.5, 0.5),\n",
    "            \"norm_std\": (0.5, 0.5, 0.5),\n",
    "            \"num_classes\": 10,\n",
    "            \"save_eval_image\": True,\n",
    "            \"set_seed\": 42 \n",
    "        }\n",
    "\n",
    "        # create model\n",
    "        mlp_h2 = MLPNet_hl2(\n",
    "            h_layer_sizes=config[\"hidden_layer_sizes\"], \n",
    "            act_fn=F.relu,\n",
    "            dropout=config['dropout'],\n",
    "            init_methode=config[\"init_w_method\"],\n",
    "            bn=config[\"batchnorm\"]\n",
    "            )\n",
    "\n",
    "        cv_train_acc_mean, cv_test_acc_mean, _, _ = model_trainer(\n",
    "            mlp_h2, config=config,\n",
    "            group=f'MLP_hL2_bn_{bn}', # _5f_cv, _seed_val, _hl_size{}, _lr{}\n",
    "            tags=['MLP', 'batchnorm'], # 5fold cv, seed val, lr\n",
    "            print_info=False, plot_eval=True, sound=True, \n",
    "            write_wandb=True\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "if False:\n",
    "    from datetime import datetime\n",
    "\n",
    "    for bn in [False, True]:\n",
    "        # Hyperparameters  \n",
    "        config = {\n",
    "            \"name\": \"CNN-simple\", \n",
    "            \"epochs\": 30,   \n",
    "            \"train_batch_size\": 32, \n",
    "            \"test_batch_size\": 32,\n",
    "            \"dataset\": \"CIFAR-10\",\n",
    "            \"lr\": 1e-2, # default 1e-3\n",
    "            \"optimizer\": 'SGD',\n",
    "            \"Regularisierung\": 'None',  # 'None', 'L1', 'L2',\n",
    "            \"L1_lambda\":0,\n",
    "            \"L2_weight_decay\":0,\n",
    "            \"batchnorm\": bn,\n",
    "            \"loss_func\": 'CrossEntropyLoss',\n",
    "            \"activation\": \"ReLU\",\n",
    "            \"image_size\": 32,\n",
    "            \"cross_validation\": False,\n",
    "            \"n_folds\": 5,\n",
    "            \"is_test_batch\": False,\n",
    "            \"start_time\": datetime.now().strftime(\"%d.%m.%Y_%H%M\"),\n",
    "            \"num_workers\": 0,\n",
    "            \"normalize\":\"zero_one\",\n",
    "            \"init_w_method\":\"kaiming_norm\",  #['uniform', 'xavier', 'normal' ,'kaiming_norm' ]\n",
    "            \"hidden_layer_sizes\": [1024, 256],\n",
    "            \"filter_sizes\": [32, 64],\n",
    "            \"dense_layers\": [512],\n",
    "            \"kernel_sizes\": 3,\n",
    "            \"padding\": 2,\n",
    "            \"stride\": 1,\n",
    "            \"pool_sizes\": [],\n",
    "            \"dropout\": 0,\n",
    "            \"norm_mean\": (0.5, 0.5, 0.5),\n",
    "            \"norm_std\": (0.5, 0.5, 0.5),\n",
    "            \"num_classes\": 10,\n",
    "            \"save_eval_image\": True,\n",
    "            \"set_seed\": 42  # [12, 16, 42, 64, 71]\n",
    "        }\n",
    "\n",
    "        # create model\n",
    "        cnn_simple = SimpleCNN(\n",
    "            filter_size=config[\"filter_sizes\"],\n",
    "            dlayers=config[\"dense_layers\"],\n",
    "            act_fn=F.relu,\n",
    "            kernel_size=config[\"kernel_sizes\"],\n",
    "            padding=config[\"padding\"],\n",
    "            stride=config[\"stride\"],\n",
    "            dropout_ch=config[\"dropout\"],\n",
    "            bn=config[\"batchnorm\"]\n",
    "            )\n",
    "\n",
    "        cv_train_acc_mean, cv_test_acc_mean, _, _ = model_trainer(\n",
    "            cnn_simple, config=config,\n",
    "            group=f'CNN__simple_bn_{bn}', # _5f_cv, _seed_val, _hl_size{}, _lr{}\n",
    "            tags=['CNN', 'batchnorm'], # 5fold cv, seed val, lr\n",
    "            print_info=False, plot_eval=True, sound=True, \n",
    "            write_wandb=True\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verwednung Batchnorm MLP und CNN**\n",
    "\n",
    "<img src=\"../01_Dokumentation/wandb_images/MLP_CNN_batchnorm.PNG\" width=\"800\" height=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "**Nutzen von Batchnorm für MLP und CNN** (ohne REG, mit SGD)  \n",
    "**MLP**: Das Modell Training findet viel schneller statt (Trainingsloss). Die Anzahl Epochen kann starch verringert werden, ein Overfitting findet mit BN bereits ab Epoche 6 statt.  \n",
    "**CNN**: Auch findet das Modell Training sehr viel schneller statt und die Trainingsdauer kann mit BN stark reduziert werden (Achtung Overfitting). Eine Verbesserung der Stabiltät konnte nicht beobachtet werden.  \n",
    "\n",
    "In Verbindung mit 'early-stopping' kann eine BN eine erhebliche Steigerung in der Trainingszeit bewirken.\n",
    "\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**4. Nutzen von Adam (ohne BN, ohne / mit REG)**   \n",
    "Evaluiere, ob Du mit Adam bessere Resultate erzielen kannst.\n",
    "    \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "**SGD** steht 'Stochastic Gradient Descent' und besitzt eine feste Lernrate. **Adam** 'Adaptive Moment Estimation' passt die Lernrate individuell an und ist bekannt für seine schnelle Konvergenz am Anfang des Modelltrainings.  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MLP** und **CNN** Optimizer Adam\n",
    "\n",
    "Folgend wird zum MLP und CNN Modell den Einsatz des Adam Optimizers getestet. \n",
    "\n",
    "**Ablauf:**  \n",
    "1. Modell mit SGD und mit/ohne Regularisierung\n",
    "1. Modell mit Adam und mit/ohne Regularisierung\n",
    "\n",
    "\n",
    "|Modell| Optimizer | Regularisierung | \n",
    "|---|----------|----------|\n",
    "|MLP-h2l| SGD|  ohne  |\n",
    "|MLP-h2l| SGD|  mit L1/dropout  | \n",
    "|MLP-h2l|  Adam | ohne  | \n",
    "|MLP-h2l|  Adam | mit L1/dropout  | \n",
    "|CNN-simple| SGD |   ohne | \n",
    "|CNN-simple| SGD |  mit L2/dropout |\n",
    "|CNN-simple| Adam |  ohne |\n",
    "|CNN-simple| Adam |  mit L2/dropout | \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "if False:\n",
    "    from datetime import datetime\n",
    "\n",
    "    for reg in ['None', 'L1']:  # 'None', 'L1'\n",
    "    # for lr in [1e-3, 1e-4, 1e-5]:\n",
    "        # Hyperparameters  \n",
    "        config = {\n",
    "            \"name\": \"MLP-hL2\", \n",
    "            \"epochs\": 18,   \n",
    "            \"train_batch_size\": 16, \n",
    "            \"test_batch_size\": 16,\n",
    "            \"dataset\": \"CIFAR-10\",\n",
    "            \"lr\": 1e-4, # default 1e-3\n",
    "            \"optimizer\": 'Adam',  #'SGD', 'Adam'\n",
    "            \"Regularisierung\": reg,  # 'None', 'L1', 'L2',\n",
    "            \"L1_lambda\": 1e-4,\n",
    "            \"L2_weight_decay\": 1e-3,\n",
    "            \"batchnorm\": False,\n",
    "            \"loss_func\": 'CrossEntropyLoss',\n",
    "            \"activation\": \"ReLU\",\n",
    "            \"image_size\": 32,\n",
    "            \"cross_validation\": False,\n",
    "            \"n_folds\": 5,\n",
    "            \"is_test_batch\": False,\n",
    "            \"start_time\": datetime.now().strftime(\"%d.%m.%Y_%H%M\"),\n",
    "            \"num_workers\": 0,\n",
    "            \"normalize\":\"zero_one\",\n",
    "            \"init_w_method\":\"kaiming_norm\",  #['uniform', 'xavier', 'normal' ,'kaiming_norm']\n",
    "            \"hidden_layer_sizes\": [1024, 512],\n",
    "            \"filter_sizes\": [32, 64],\n",
    "            \"dense_layers\": [512],\n",
    "            \"kernel_sizes\": 3,\n",
    "            \"padding\": 1,\n",
    "            \"stride\": 1,\n",
    "            \"pool_sizes\": [],\n",
    "            \"dropout\": 0.2,\n",
    "            \"norm_mean\": (0.5, 0.5, 0.5),\n",
    "            \"norm_std\": (0.5, 0.5, 0.5),\n",
    "            \"num_classes\": 10,\n",
    "            \"save_eval_image\": True,\n",
    "            \"set_seed\": 42 \n",
    "        }\n",
    "\n",
    "        # create model\n",
    "        mlp_h2 = MLPNet_hl2(\n",
    "            h_layer_sizes=config[\"hidden_layer_sizes\"], \n",
    "            act_fn=F.relu,\n",
    "            dropout=config['dropout'],\n",
    "            init_methode=config[\"init_w_method\"],\n",
    "            bn=config[\"batchnorm\"]\n",
    "            )\n",
    "\n",
    "        cv_train_acc_mean, cv_test_acc_mean, _, _ = model_trainer(\n",
    "            mlp_h2, config=config,\n",
    "            group=f'MLP_hL2_adam_reg_{reg}', # _5f_cv, _seed_val, _hl_size{}, _lr{}\n",
    "            tags=['MLP', 'adam'], # 5fold cv, seed val, lr\n",
    "            print_info=False, plot_eval=True, sound=True, \n",
    "            write_wandb=True\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "if False:\n",
    "    from datetime import datetime\n",
    "\n",
    "    for reg in ['None', 'L2']:\n",
    "    # for lr in [1e-5, 1e-4, 1e-3, 1e-2]:\n",
    "        # Hyperparameters  \n",
    "        config = {\n",
    "            \"name\": \"CNN-simple\", \n",
    "            \"epochs\": 18,   \n",
    "            \"train_batch_size\": 32, \n",
    "            \"test_batch_size\": 32,\n",
    "            \"dataset\": \"CIFAR-10\",\n",
    "            \"lr\": 1e-4, # default 1e-3\n",
    "            \"optimizer\": 'Adam',  #'SGD', 'Adam'\n",
    "            \"Regularisierung\": reg,  # 'None', 'L1', 'L2',\n",
    "            \"L1_lambda\":1e-4,\n",
    "            \"L2_weight_decay\":1e-3,\n",
    "            \"batchnorm\": False,\n",
    "            \"loss_func\": 'CrossEntropyLoss',\n",
    "            \"activation\": \"ReLU\",\n",
    "            \"image_size\": 32,\n",
    "            \"cross_validation\": False,\n",
    "            \"n_folds\": 5,\n",
    "            \"is_test_batch\": False,\n",
    "            \"start_time\": datetime.now().strftime(\"%d.%m.%Y_%H%M\"),\n",
    "            \"num_workers\": 0,\n",
    "            \"normalize\":\"zero_one\",\n",
    "            \"init_w_method\":\"kaiming_norm\",  #['uniform', 'xavier', 'normal' ,'kaiming_norm' ]\n",
    "            \"hidden_layer_sizes\": [1024, 256],\n",
    "            \"filter_sizes\": [32, 64],\n",
    "            \"dense_layers\": [512],\n",
    "            \"kernel_sizes\": 3,\n",
    "            \"padding\": 2,\n",
    "            \"stride\": 1,\n",
    "            \"pool_sizes\": [],\n",
    "            \"dropout\": 0.2,\n",
    "            \"norm_mean\": (0.5, 0.5, 0.5),\n",
    "            \"norm_std\": (0.5, 0.5, 0.5),\n",
    "            \"num_classes\": 10,\n",
    "            \"save_eval_image\": True,\n",
    "            \"set_seed\": 42  # [12, 16, 42, 64, 71]\n",
    "        }\n",
    "\n",
    "        # create model\n",
    "        cnn_simple = SimpleCNN(\n",
    "            filter_size=config[\"filter_sizes\"],\n",
    "            dlayers=config[\"dense_layers\"],\n",
    "            act_fn=F.relu,\n",
    "            kernel_size=config[\"kernel_sizes\"],\n",
    "            padding=config[\"padding\"],\n",
    "            stride=config[\"stride\"],\n",
    "            dropout_ch=config[\"dropout\"],\n",
    "            bn=config[\"batchnorm\"]\n",
    "            )\n",
    "\n",
    "        cv_train_acc_mean, cv_test_acc_mean, _, _ = model_trainer(\n",
    "            cnn_simple, config=config,\n",
    "            group=f'CNN__simple_adam_reg_{reg}', # _5f_cv, _seed_val, _hl_size{}, _lr{}\n",
    "            tags=['CNN', 'adam', 'reg'], # 5fold cv, seed val, lr\n",
    "            print_info=False, plot_eval=True, sound=True, \n",
    "            write_wandb=True\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verwendung von Adam für MLP**\n",
    "\n",
    "<img src=\"../01_Dokumentation/wandb_images/MLP_hl2_sgd_adam.PNG\" width=\"800\" height=\"400\">\n",
    "\n",
    "**Verwendung von Adam für CNN**\n",
    "\n",
    "<img src=\"../01_Dokumentation/wandb_images/CNN_simple_sgd_adam.PNG\" width=\"800\" height=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "**Nutzen von Adam MLP und CNN** (ohne REG, mit SGD)  \n",
    "Für das Testen von Adam wurde die Anzahl Epochen verkürzt und so das Overfitting bereits verhindert. Eine Regularisierung wird daher nur sehr gering angewendet.\n",
    "\n",
    "**MLP**: Bei den Modellen ohne Regularisierung sind die Unterschiede zwischen SGD und Adam nicht sehr gross. Die Lernrate für Adam musste jedoch auf $lr=1^{-4}$ verringert werden, damit das Modell etwas lernte. Wenn eine Regulierung verwendet wird, findet das Training mit Adam deutlich schneller und auch stabiler statt.   \n",
    "\n",
    "**CNN**: In beiden Fällen, mit und ohne Regularisierung, wird das Training beschleunigt. Auch die Stabilität auf dem Validation loss und Test Accuracy ist deutlich zu sehen. \n",
    "\n",
    "Dadurch, dass die Lernrate während dem Training angepasst werden kann, überzeugt Adam mit schnelleren Trainings und auch durch einen stabileren Verlauf des Validationloss sowie bei der Test Accuracy.\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fazit und Learnings\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "In dieser Challenge wurden verschiedene Modellarchitekturen ausprobiert und den Einfluss der Hyperparameter untersucht. Es zeigte sich, dass die Modellarchitektur einen starken Einfluss auf die Modellperformance hat (MLP vs CNN). Die Wahl der Architektur hängt, nicht zu letzt, von der Aufgabenstellung ab und kann nicht durch ein umfassendes Hyperparameter Tunning korrigiert werden.  \n",
    "\n",
    "Neben der Modellarchitektur sollten die Hyperparameter geziehlt optimiert werden, da der Umfang der Hyperparamter sehr schnell sehr grosse Dimensionen annehmen kann. Gute Tools wie wandb.ai können dabei helfen die Übersicht der Experimente überschaubar zu halten. Es zeigte sich auch als sinnvoll die Experimente und Resultate kurz zu beschreiben und so das weitere Vorgehen zu definieren.\n",
    "\n",
    "Hinsichtlich Hyperparameter: Die Verwendung von Adam zeigte mehr Flexibiltät bei der Wahl der Lernrate. Sowie SGD verfügt auch Adam über weitere Parameter die noch genauer angeschaut werden sollen (Parameter zu Momentum). Mit der Regularisierung konnte gezeigt werden, dass dem Overfitting entgegen gewirkt werden kann. Neben L1 und L2 zeigte dropout und early-stopping gute Anwendungsmöglichkeiten. Die Frage welche Regularisierung in welchem Fall angewendet werden soll, ist noch offen. Kombinationen von Regularisierung scheinen denkbar aber werden schwieriger zu interpretieren. Überrascht hat die Batchnorm, diese hat das Training deutlich schneller gemacht. BN sollte jedefall als Hyperparameter im Modelltraining zur Verfügung stehen.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ende Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "e452ba78c6e1c5f07381d012e3449bb8aff006d5d5ee6ce630663b7f08ee76a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
