{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning - MCH2\n",
    "Fachdozent: Martin Melchior     \n",
    "Student: Manuel Schwarz   \n",
    "HS23\n",
    "\n",
    "Dieses Notebook bearbeitet die Mini-Challenge 2 des Moduls Deep Learning (del).   \n",
    "Die Performance der Modelle wurde mit **wandb.ai** aufgezeichnet und kann [hier](https://wandb.ai/manuel-schwarz/del-mc2/workspace?workspace=user-manuel-schwarz) eingesehen werden.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Aufgabenstellung:</b> Eine Blaue Box beschreibt die Aufgabe aus der Aufgabenstellung 'SGDS_DEL_MC1.pdf' \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Antworte:</b> Eine Grüne Box beschreibt die Bearbeitung / Reflektion der Aufgabenstellung\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import torch\n",
    "import wandb\n",
    "import random\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from tqdm import tqdm \n",
    "from datetime import datetime\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device: ', device)\n",
    "\n",
    "# sound\n",
    "import time\n",
    "import winsound\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufbau Modellierung und Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Überlege Dir, welche Modell-Architektur Sinn machen könnte. Mindestens zwei Modell-Varianten sollen aufgebaut werden, die miteinander verglichen werden sollen.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "Für die del-MC2 Challenge wird das Modell vom Paper Vinyals et al `Show and Tell: A Neural Image Caption Generator` nachgebaut. Das Paper entwickelte ein Modell welches für Bilder eine Bildbeschreibung erstellt. Für die verwendeten Daten wird das `Flickr 8k` Datenset verwendet. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten Flickr 8k lesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder = './data/Images'\n",
    "captions_file = './data/captions.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_captions = pd.read_csv('./data/captions.txt', sep='\\t', header=None)\n",
    "pd_captions.columns = ['full_caption']\n",
    "pd_captions[['image_name', 'caption']] = pd_captions['full_caption'].str.split(',', n=1, expand=True)\n",
    "pd_captions.to_csv('./data/pd_captions.csv', index=False)\n",
    "pd_captions.drop('full_caption', axis=1, inplace=True)\n",
    "pd_captions.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im `caption.txt` File ist der Bildnamen und die Bildbeschreibung (caption) hinterlegt. Pro Bild stehen fünf Captions zur Verfügung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 5\n",
    "\n",
    "example_image_path = f'{images_folder}/{pd_captions.image_name[image_id]}'\n",
    "example_caption1 = pd_captions.caption[image_id+0]\n",
    "example_caption2 = pd_captions.caption[image_id+1]\n",
    "example_caption3 = pd_captions.caption[image_id+2]\n",
    "example_caption4 = pd_captions.caption[image_id+3]\n",
    "example_caption5 = pd_captions.caption[image_id+4]\n",
    "image = Image.open(example_image_path)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.title(f'{example_caption1} \\n {example_caption2} \\n {example_caption3} \\n {example_caption4} \\n {example_caption5}')\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufteilung in Trainings- und Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Anzahl Captions: {len(pd_captions)}')\n",
    "unique_images = pd_captions.image_name.unique()\n",
    "print(f'Anzahl Bilder: {len(unique_images)}')\n",
    "\n",
    "unique_images = list(pd_captions.image_name.unique())\n",
    "train_images = random.sample(unique_images, k=int(len(unique_images) * 0.8))\n",
    "test_images = list(set(unique_images) - set(train_images))\n",
    "\n",
    "print(f'Länge Trainingsset: {len(train_images)}')\n",
    "print(f'Länge Testset: {len(test_images)}')\n",
    "\n",
    "pd_train_set = pd_captions[pd_captions.image_name.isin(train_images)]\n",
    "pd_test_set = pd_captions[pd_captions.image_name.isin(test_images)]\n",
    "pd_train_set.to_csv('./data/train_captions.csv', index=False)\n",
    "pd_test_set.to_csv('./data/test_captions.csv', index=False)\n",
    "\n",
    "print(f'Länge Trainingsset: {len(pd_train_set)}')\n",
    "print(f'Länge Testset: {len(pd_test_set)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd_captions = pd.read_csv('./data/train_captions.csv')\n",
    "test_set = pd_captions = pd.read_csv('./data/test_captions.csv')\n",
    "\n",
    "train_set.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 5\n",
    "\n",
    "example_image_path = f'{images_folder}/{train_set.image_name[image_id]}'\n",
    "example_caption1 = train_set.caption[image_id+0]\n",
    "example_caption2 = train_set.caption[image_id+1]\n",
    "example_caption3 = train_set.caption[image_id+2]\n",
    "example_caption4 = train_set.caption[image_id+3]\n",
    "example_caption5 = train_set.caption[image_id+4]\n",
    "image = Image.open(example_image_path)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.title(f'{example_caption1} \\n {example_caption2} \\n {example_caption3} \\n {example_caption4} \\n {example_caption5}')\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erstellen des Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder = './data/Images'\n",
    "captions_file = './data/captions.txt'\n",
    "\n",
    "class Flickr8kDataset(Dataset):\n",
    "    def __init__(self, images_folder, captions_file, transform=None):\n",
    "        self.images_folder = images_folder\n",
    "        self.transform = transform\n",
    "\n",
    "        with open(captions_file, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        self.captions = {}\n",
    "        for line in lines:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) == 2:\n",
    "                image_id, caption = parts\n",
    "                if image_id[:-2] not in self.captions:\n",
    "                    self.captions[image_id[:-2]] = []\n",
    "                self.captions[image_id[:-2]].append(caption)\n",
    "\n",
    "        self.image_ids = list(self.captions.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        image_path = os.path.join(self.images_folder, image_id)\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        captions = self.captions[image_id]\n",
    "        return image, captions\n",
    "\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "flickr8k_dataset = Flickr8kDataset(\n",
    "    images_folder=images_folder,\n",
    "    captions_file=captions_file,\n",
    "    transform=transformations\n",
    ")\n",
    "\n",
    "flickr8k_dataloader = DataLoader(dataset=flickr8k_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "for images, captions in flickr8k_dataloader:\n",
    "    print(images.shape)\n",
    "    print(captions[0]) \n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_cuda117_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
